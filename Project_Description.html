<!doctype html>
<html lang="en">
<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">

  <!-- Bootstrap CSS -->
  <link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css"
        integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" rel="stylesheet">

  <!-- Bootstrap Icons -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" rel="stylesheet">

  <!-- A3 CSS -->
  <link href="css/A3.css" rel="stylesheet" type="text/css">

  <!-- Bootstrap Sidebars -->
  <link href="css/sidebars.css" rel="stylesheet" type="text/css">

  <title>Project Description</title>
</head>

<body>

<!-- Sidebar Navigation -->

<div class="wrapper d-flex align-items-stretch">

  <nav class="p-4 bg-white side-nav">
    <a class="d-flex align-items-center pb-3 mb-3 link-dark text-decoration-none border-bottom" href="A3TOC.html">
      <span class="fs-5 fw-semibold">A3 Our IT Project</span>
    </a>

    <ul class="list-unstyled ps-0">

      <li class="mb-1">
        <a aria-expanded="false" class="btn btn-toggle rounded collapsed"
           data-bs-target="#tp-collapse" data-bs-toggle="collapse" role="button">
          Team Profile
        </a>
        <div class="collapse mx-3" id="tp-collapse">
          <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
            <li><a class="link-dark rounded" href="Team_Profile.html#TeamName">Team Name</a></li>
            <li><a class="link-dark rounded" href="Team_Profile.html#chris">Chris</a></li>
            <li><a class="link-dark rounded" href="Team_Profile.html#gerard">Gerard</a></li>
            <li><a class="link-dark rounded" href="Team_Profile.html#liljana">Liljana</a></li>
            <li><a class="link-dark rounded" href="Team_Profile.html#nicole">Matthew</a></li>
            <li><a class="link-dark rounded" href="Team_Profile.html#matt">Nicole</a></li>
          </ul>
        </div>
      </li>

      <li class="mb-1">
        <a aria-expanded="false" class="btn rounded collapsed" href="Tools.html">
          Tools
        </a>
      </li>

      <li class="mb-1">
        <a aria-expanded="false" class="btn btn-toggle rounded collapsed"
           data-bs-target="#pd-collapse" data-bs-toggle="collapse">
          Project Description
        </a>
        <div class="collapse mx-3" id="pd-collapse">
          <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
            <li><a class="link-dark rounded" href="Project_Description.html#overview">Overview</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#aims">Aims</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#plans">Plans & Progress</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#roles">Roles</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#scope">Scope & Limits</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#tools">Tools & Technologies</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#testing">Testing</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#timeframe">Timeframe</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#risks">Risks</a></li>
            <li><a class="link-dark rounded" href="Project_Description.html#group">Group Processes & <br> Communications</a>
            </li>
          </ul>
        </div>
      </li>

      <li class="mb-1">
        <a aria-expanded="false" class="btn rounded collapsed" href="Skills&Jobs.html">
          Skills & Jobs
        </a>
      </li>

      <li class="mb-1">
        <a aria-expanded="false" class="btn rounded collapsed" href="Artefacts.html">
          Artefacts
        </a>
      </li>

      <li class="mb-1">
        <a aria-expanded="false" class="btn rounded collapsed" href="Group_Reflection.html">
          Group Reflection
        </a>
      </li>
    </ul>

  </nav>

  <!-- CONTENT GOES HERE -->

  <div class="section">

    <div class="container-fluid position-sticky p-0 top-0 w-100">
      <div class="hero-image">
        <h1 class="display-2 text-white text-center p-5">Project Description</h1>
      </div>
    </div>

    <div class="w-50 mx-auto">

      <h2 id="overview">Overview</h2>

      <h4>Topic:</h4>
      <p>Our project, “Drive Aware”, involves the development of an iOS app with a corresponding Watch OS app that will
        monitor the biometrics of vehicle drivers. The hope is that in doing this the app will be able to alert them of
        the onset of fatigue caused by sustained periods of driving. The App will collect and analyse data from the
        various sensors built in since the Apple iPhone n11 and the Apple Watch 6. The front facing camera of the iPhone
        will be used to track and analyse the driver’s visual cues, searching for signs of driver fatigue. Using AI
        technology and deep learning, the Drive Aware App will be able to recognise and analyse visual cues such as
        changes in posture, blinking and yawning frequency.  The corresponding watch application will monitor heart rate
        and actigraphy which will be used in conjunction with other data to assess the driver’s likely level of
        vigilance.</p>

      <p> Alert systems will be in place in the event of a crash or in the event a driver is unresponsive to requested
        actions. The Drive Aware App will have the ability designated contacts and ultimately emergency services in such
        situations. </p>
        
      <h4> Motivation:  </h4>
      <p> According to Budget Direct 1,195 people were killed in road-related deaths in 2019 (Insurance, Statistics and
        2020, 2021). This equates to over 3 people per day. 36% of fatal crashes occurred in major cities and single
        vehicle accidents made up just under 50% of fatal crashes. Thankfully, there has been a decrease in road deaths
        since 1970 largely attributed to stricter road safety laws, measures put in place by transit authorities and
        safer vehicle standards (Insurance, Statistics and 2020, 2021). However, it is our belief that a single
        preventable fatality on our roads is one too many and it is this belief that inspired the development of the
        Drive Aware App.  </p>

      <p> Driver fatigue is ranked 4th out of the 5 most common causes of fatal vehicle accidents in Australia (‘Fatal
        Five’ Causes of Car Accidents in Australia, 2021) and is considered as dangerous as driving under the influence
        of alcohol and is much harder to detect than drunk driving with driver’s simply unaware of how their driving and
        cognitive abilities can be impaired when driving tired (Fisher et al. 2011). The graph below illustrates this,
        clearly showing that self-reporting of fatigue is not adequately reliable. Worryingly, research has also
        indicated that the standard two hour continuous driving limit is too high with people varying considerably in
        their safe limit and most showing considerably decreased concentration after 80 minutes (Ting et al. 2008). </p>

      <img alt="awakevsasleep" class="rounded mx-auto d-block img-fluid" src="assets/awakevsasleep.jpg">
      <p class="small"><em> Edited Graph taken from “The Process of Falling Asleep” (Ogilvie 2001) showing the variation
        in active and passive response (Ogilvie 1984) in comparison to Hori’s 9 hypnagogic EEG stages with the
        simplified standard sleep scoring (Hori, Hayashi & Tanaka 1998) as well as self-reporting and heart rate changes
        (Pivik & Busby 1996).  For the purposes of this project, the heart rate changes in comparison to both
        self-reporting and active response times are particularly noteworthy. They demonstrate that drivers may be
        unaware of the decrease in their response time as tiredness progresses and that there may be alterations in
        heart rate before the driver is conscious that they have become fatigued</em>.  </p>

        
      <h4> Landscape: </h4>
      <p> It is no secret that our lives are increasingly reliant on modern technology. With this feeding our urge for
        instant gratification and the way in which we quickly access news and other information changing due to
        ownership of mobile phones approaching 80% of the Australian population, (Australia: smartphone users 2017-2025
        | Statista, 2021). The way in which we interact with technology is changing. Furthermore, the use of wearable
        devices is becoming commonplace meaning people are increasingly used to having their biometrics monitored
        (Granwal 2020). Because of this, we believe there will be demand for an App which can track and monitor
        biometric vital signs associated with driver fatigue.  </p>
        
      <p> The Drive Aware App will be incorporating some of the top 14 mobile trends as identified by Quicksprout (14
        Mobile Trends That Are Dominating 2021, 2021).  </p>
        
      <h5>These include:</h5>
      <li>Facial movement analysis. The App will use and collect data to recognise driver fatigue cues by monitoring a
        driver’s face through the front facing iPhone camera.
      </li>
        
      <li> Syncing wearable technology with mobile devices. The Drive Aware App is an iOS app supported by a Watch OS
        App. With data being collected from sensors within the Apple Watch.
      </li>
        
      <li> Location based technology. GPS will be used to help locate drivers should they be involved in a crash or
        accident and may be incapacitated.
      </li>
       
      <li> Artificial intelligence (AI). The Drive Aware App will be able to learn and then recognise a driver’s visual
        cues to determine if they are suffering from the effects of driver fatigue.
      </li>
        
        
      <li> By working on this project and by bringing it from theoretical stage to tangible results and towards a
        working prototype, the Drive Aware Tech Team hopes to show future employers how we, both as a team and as
        individuals, have developed our IT skills. From researching technology and background information, evaluating
        how it can be incorporated and used successfully within the App to learning how to use development tools and
        technology. Ultimately, we are proud to have taken the initial steps required to bring the Drive Aware App to
        market.
      </li>
      <br><br>


      <h2 id="aims">Aims</h2>

      <p> The central aim of the project is to produce a mobile application that monitors and analyses a driver’s
        biometrics and alerts them to signs of fatigue.  Given the timeframe available to the group, the realistic aim
        of the group is to take this concept as far as possible towards a working prototype.  To achieve this, the
        central aim can be broken down into smaller goals including: </p>
        
      <p><b> Goal 1: The Development of a proof-of-concept prototype. </b>
          
        <br> To fully understand and be able to explain how the Drive Aware App is to work, a prototype is required.
        This will enable our team to demonstrate key functions of the App and show how these will operate while the App
        is in use by the driver. The key functions we would like to demonstrate include an initial setup screen,
        calibration of a visual monitoring system, a normal driving demonstration, and a crash event demonstration. </p>
       
        
      <p> Initial setup screen - On initial setup of the Drive Aware App, the driver will need to complete their
        Profile. This step will ensure the driver has provided the necessary information to allow the Drive Aware App
        runs effectively. Essential profile information includes the drivers details already stored in the iPhone’s
        Health App (Wotton, 2021 - a). Health App information that will be confirmed includes; name, date of birth, sex,
        weight, height, blood type, and whether the driver is taking any medications that may affect their heart rate
        (Use the Health app on your iPhone or iPod touch, 2021). </p>
        
        
      <p> Calibration of visual monitoring system - This will involve visual testing of the driver by asking them to
        perform a series of simple tasks. Tasks will include looking at the front facing camera, the driver will be
        prompted to blink several times, move their gaze up and down as well as left and right, and perform a simulation
        of yawning by opening and closing their mouth. (Wotton, 2021 - b). </p>
        
      <p> Normal driving demonstration - During the normal course of driving the Drive Aware App will continually
        monitor the driver visually and biometrically, it will also collect and analyse the data from the various
        sensors which are built into the iPhone and Apple Watch. Data from the iPhone includes the accelerometer, GPS,
        timer, and camera. Apple Watch data will include the accelerometer, gyroscope, heart rate monitor, and GPS.
        (Wotton, 2021 - c) </p> 
        
      <p> Crash event demonstration - A crash event will be recognised by the Drive Aware App should there be a sudden
        change in data being collected by the accelerometer and GPS, (Apple Developer Documentation, 2021) for example a
        sudden change would include a rapid decrease in speed caused by a crash. Upon this event, the Drive Aware App
        will attempt to contact designated contacts through the iPhone and ultimately the emergency services if
        needed. </p> 
        
      <p><b> Goal 2: Demonstration of the intended data flow. </b>
          
        <br> A data flow diagram (DFD) maps out the flow of information for any process or system. It uses defined
        symbols such as rectangles, circles and arrows, plus short text labels. These show data inputs, outputs, storage
        points and the routes between each destination. (What is a Data Flow Diagram, 2021). The data flow diagrams will
        be used as a key artifact for this project with the information outlined being used as a base for the
        demonstration of key functions of the Drive Aware App prototype. Data flow diagrams will be completed for the
        following key functions, initial setup screen, calibration of visual monitoring system, normal driving
        demonstration and crash event demonstration. </br>
          
      <p><b> Goal 3: Planning of the code structure of the application. </b>
          
        <br> Coding for the Drive Aware App will be completed using Apple native developer tools such as Swift UI in
        conjunction with the suite of Apple developer technologies. As noted by Yu, creating code on native developer
        tools offers a better user experience then using a cross platform solution to build a single app for both iOS
        and Android devices (Yu, 2021). By focussing on building the Drive Aware App for iOS and Watch OS in the initial
        stages, our team will concentrate on building more cohesive app at launch for a single platform. <br>
          
      <p><b> Goal 4: Assessment of additional devices that will help in identifying driver fatigue. </b>
          
        <br> Further discussions and possible implementation to occur regarding the benefits and wearability of an EEG
        headband which will work in conjunction with the other planned sensors to monitor driver fatigue. EEG headband
        signals are known to be a reliable indicator of fatigue and drowsiness; however, they have not been widely used
        due to their size and restrictive moveability (Rohit et al., 2017). There has been significant advancements in
        the technology which may make it feasible addition to the Drive Aware App.  </br>

      <p><b> Goal 5: Partner with a commercial entity – Car Insurance Company or Similar.</b>

        <br> Although well beyond the scope of this assignment, to increase the user base of the service and strive for
        continued growth, we will attempt to secure a commercial relationship with an insurance provider or a driving
        association. The benefits in doing so would include being associated with a trusted and reputable brand which
        would likely see the Drive Aware App considered in the same light. This could increase profitability as a
        subscription payment model to end users of such a company could be implemented or a commercial agreement
        considered directly with the company. There is precedence for the use of mobile applications as a tool for
        insurance companies which is what inspired us to consider this avenue. Aviva, as part of its insurance operation
        in the United Kingdom, incentivises some customers to use and application while driving that assesses the safety
        of their driving. Should the application deem the driving to be of a certain standard, the customer may be
        rewarded with reduced premiums (Aviva 2020; Baker 2016). Drive aware could perhaps be used in a similar way, to
        reward drivers for their use of the app and for taking breaks when advised to thereby reducing risk for an
        insurer and decreasing the chances of a traffic accident. Alternatively, for a fee, a licencing agreement could
        be reached whereby Drive Aware could be offered as a free benefit to an insurer’s customers or the members of a
        driving organisation.
        <br><br>


      <h2 id="plans">Plans & Progress</h2>

      <p>
        The Drive Aware project started off as the Assignment 1 project Idea of Matthew Wotton: one of our team
        members. The original concept was to develop an application for a wearable device, the Apple Watch, and for the
        iPhone that would monitor drivers and alert them to signs of fatigue (Wotton 2021). This is a widely recognised
        problem for truck drivers, they work long hours which leads to exhaustion

        <a href="https://www.cannonlogistics.com.au/blog/fatigue-management-truck-drivers-need-know/">
          (Fatigue Management: What Truck Drivers Need To Know, 07/05/21) </a>

        in turn creating a hazardous environment for other
        road users.

        <a href="https://www.bitre.gov.au/publications/ongoing/fatal_heavy_vehicle_crashes_quarterly ">
          (Fatal Heavy Vehicle Crashes Australia—Quarterly Bulletins, (07/05/21)
        </a>

        Our group quickly became fond of polls as
        a way of coming to decisions and after a look at all the group’s Assignment 1 projects, Nicole organised a poll
        to decide which one we would like to work on together with Matthew’s coming out on top.
      </p>

      <p>
        As commenced our research in Assignment 2, we received some valuable constructive criticism from Daniel,
        Waymo’s System Engineering Manager

        <a href="https://s3903477.github.io/ITT-Assignment-2/Interview.html">(Josevski 2021)</a>

        Gerard conducted a literature review of scholarly articles relating to driver fatigue as well as the physiology
        and measurement of stages of the onset of sleep which concluded with recommendations on which biometrics may be
        worth measuring and why <a href="Artefacts.html">(See artefacts)</a>. This was re-enforced by research subsequently undertaken by Liljana.

        <a href="https://onlinelibrary.wiley.com/doi/10.1002/ajhb.23541"> (Samson, 07/05/21)
        </a>

      </p>

      <p>
        After a team discussion, we decided our aim for the user market would be any vehicle driver, such as every day commuters who also suffer from fatigue
        <a href="https://www.optalert.com/driver-fatigue-why-does-driving-make-you-tired/"> ( Driver fatigue: why does
          driving make you tired?, 2021) </a>
          It is well established that as a driver becomes relaxed during monotonous driving, and when there is no stimulus, the
            driver will become drowsy (Fisher et al. 2011). This can have fatal consequences. Because of this, another potential user
             of Drive Aware may be holiday makers on long road trips with their families, especially now with covid 19 putting severe
             restrictions on overseas travel <a
                href="https://covid19.homeaffairs.gov.au/leaving-australia"> (COVID-19 and the border Leaving Australia,07/05/21).
               </a>This has prompted families to travel more within our country and to use caravans more,  <a
                href="https://www.vicroads.vic.gov.au/safety-and-road-rules/vehicle-safety/safe-caravanning"> (Safe
              caravanning) [07/05/21]</a>which are large and can be dangerous if the driver is not fully alert. Sadly, these situations
               are possible and can have severe consequences so,
               the drive aware app would be beneficial to these drivers too, and not just the professional driver. </p>
      <p>  We also decided, to begin with at least, on limiting the application’s accessibility to the iPhone and Apple Watch

        <a href="https://support.apple.com/en-au/guide/watch/apd99e3c6a68/watchos"> (Apple Watch User Guide)
          [07/05/21] </a>

         and in future to consider developing it on Android with a corresponding smart watch.
         This would not restrict the user market in the long term and issues would be identified on a single platform rather
          than needing to alter its construction to accommodate both Android and iOS.  Additionally, we believe that starting
          with Apple for our prototype will be simpler as two of our team members have Apple Watches and understand their use
           and functionality.

        <a href="https://support.apple.com/en-au/guide/watch/apd99e3c6a68/watchos">(Apple Watch User Guide)
          [07/05/21] </a>
      </p>

      <br>
      <h3>The Drive Aware App Plan </h3>
      <h5>Hand drawn flow chart drafts. </h5>
      <img alt="hand drawn flow charts" class="img-fluid" src="assets/handdrawnflow.png">
      <br>
      <p>We started off with a hand drawn sketch outlining basic functionality, indicating how the app should look when
        opened including pop ups allowing the accessibility of data gathered from the Health App and available on the
        iPhone. After some discussion and research, we decided that this should then be followed by a prototype
        developed with Figma.<a href="https://www.figma.com/"> (Minds meeting minds is how great ideas meet the world)
          [07/05/21] </a> The prototype will allow us to show our vision and enable us to present the idea to others.
      </p>
      <p>The group believe that the components needed for the application’s operation should be easily accessible
        wearable smart technology and, initially at least, devices that the user currently owns. This enables the app to
        be interchanged to any vehicle as the equipment needed is neither cumbersome or inbuilt. This enables mobility
        and flexibility, also affordability compared to some similar technologies currently available offering driver
        monitoring such as Seeing Machines <a
            href="https://www.proactiveinvestors.co.uk/companies/news/213919/seeing-machines-sees-bright-future-for-driver-monitoring-technology-213919.html">
          (Seeing Machines sees bright future for driver monitoring technology) [07/05/21] </a></p>
      <h4>Flow charts created by team members are below.</h4> <a href="Artefacts.html">(Further details in Artefacts) </a>
      <img alt="more flow charts from group members" class="img-fluid" src="assets/otherflowcharts.png">
      <br>
      <br>
      <p>The images above of the multiple rough drafts show the progress of the flow of the prototype before we
        started using<a href="https://www.figma.com/"> Figma</a>. Among other things, we had inspiration for the visual
        aspects of the activity of the biometrics, from looking at the health app on one of our iPhones. This inspired
        us to display daily statistics and have a line graph showing the length of the drive with the biometric levels.
        This information can also be displayed as weekly statistics showing a comparison of the wakefulness throughout
        the week. Once the app has the user details and you are logged in, we have decided to add an extra screen for
        users to agree to the<a href="https://www.termsfeed.com/blog/5-reasons-need-terms-conditions/"> terms and
          conditions</a>. This was a result of assessing the risks associated with the application’s use as well as to
        limit liability (see Risks). Should user not agree to the terms: Drive Aware will not be available to assist
        them. After this, when the user presses start, the screen will go back to the user’s normal home screen and will
        have an indicator icon showing that the app is operating, this has been designed this way to minimise driver
        distraction. Another example of a function operating this way is the “personal hotspot” which, when one clicks
        on the menu section. The Data history will be stored in the app and will use the current technology used with
        the health app to gather and translate the user’s data. In the set-up stage of the Drive Aware App, the user
        will need to allow access to the <a href="https://www.apple.com › au › ios › health"> Health App</a> which will
        also allow access to the <a href="https://support.apple.com/en-us/HT207021"> Medical ID </a> which consists of
        the biometrics and emergency contacts. </p>
      <h4>Inspiration from the Health App </h4>
      <br>
      <img alt="inspo from health app" class="img-fluid" src="assets/inspofromhealth.png">
      <br>
      <br>
      <p>The group proposes to use a similar technology to the facial recognition technology currently in smart phones
        such as the wire frame to determine the user’s facial distinctions. <a
            href="https://support.apple.com/en-au/HT208108"> (About Face ID advanced technology) [07/05/21]</a> This
        will also allow the app to perceive the eyes as they appear when opened, to then be able to monitor the drivers
        eye movements when the app is in use and to enable warnings when there is a detection of fatigue occurring. This
        will also be in the initial use of the app in the set-up stage of the Drive Aware App, the user will need to
        allow access to the Health App which includes access to Medical ID including biometrics and emergency contacts.
      </p>
      <br>
      <h4>The Reaction Test Game</h4>
      <br>
      <p>The reaction test game was proposed as a solution to the problems caused by drivers lack of insight into their own
         fatigue levels (Ting et al. 2008).  The original game involved colour selection time to ascertain reaction time
         (see image below). After some thought we have considered that we would run into some obstacles with the reaction test
          game. We thought by changing it from the assorted colours on the pallet we initially had in A2, to something more shape
           based as the colour palette are too like one another and might confuse some users if they cannot identify the correct
           shade stated. The game would be especially challenging for colour blind people.  <a
            href="https://www.healthline.com/health/eye-health/what-do-colorblind-people-see#:~:text=Color%20blindness%20is%20usually%20an,differentiate%20among%20shades%20of%20colors.&text=Research%20suggests%20that%20color%20blindness,yellow%2C%20and%20complete%20color%20blindness.">
          (What Do Colour blind People See?) [07/05/21] </a>
      Because of the issues raised above, the game was altered.  The current design involves the user pressing on a left or
      right arrow when prompted.  The player’s reaction time is tested three times and if the test is failed by the driver,
       they will be advised to rest for longer before trying the game again and, if they pass the test, continuing their journey.
      </p>
      <img alt="game concept images" class="img-fluid" src="assets/reactiongame.png">
      <br>
      <br>
      <p>We will reconsider the game and make it more complex as the app development progresses. However,
         we have agreed that for the prototype, it should retain this format. Future game ideas include a
         simple driving  simulator which presents hazards for the player to avoid to assess the alertness of the driver.
         A game such as that which would resonate with the purpose of Drive Aware would be ideal. </p>
         <br>
         <h4>Prototype Development: </h4>
      <h6>Ideas we considered for the UI before we completed our prototype. </h6>
      <img alt="userinterface plan images" class="img-fluid" src="assets/figmatemplate.png">
      <br>
      <br>
      <ol>
        <li> Showing the control centre icon is in operation.
        </li>
        <li> Facial recognition technology
        </li>
        <li> Map’s location-accelerometer and gyroscope
        </li>
        <li> Contacts enabled to contact emergency services or person in an emergency.
        </li>
        <li> Home screen when the app is in use will appear like this but with icon on the top bar to indicate its
          operating.
        </li>
        <li> Voice deactivation screen with Siri as an example.
        </li>
        <li> The main screen in the app will be the same image we used for our banner in A2 without the avatars as it
          really does suit the concept of our app, having the roads and graphs which indicate measuring of data.
        </li>
      </ol>
      <p><a href="https://www.figma.com"> Figma templates [07/05/21]</a></p>
      <br>
      <p>The application will run in the background on the device once it has been activated and then will continue to operate
        through the smart watch measuring biometrics  <a
            href="https://onlinelibrary.wiley.com/doi/10.1002/ajhb.23541"> (David R. Samson,07/05/21) </a>thus preventing the iPhone or Apple watch to be of
            a distraction to the driver. We considered a coloured indicator, for instance green, at the top of the screen indicating that the app is in fact
             operating while not causing a distraction. For the application to function, the iPhone needs to be securely mounted on the dashboard in sight of
             the driver’s eyes to enable the forward-facing camera to function and detect movements. The camera will monitor the length of time the user has
              closed their eyes whether blinking or otherwise. An extended blink can indicate that a driver is becoming tired (Fisher et al. 2011). Securing
              the device in this manner is also recommended by Vic Roads  <a
            href="https://www.vicroads.vic.gov.au/safety-and-road-rules/driver-safety/mobile-phones-and-driving">(Mobile
          phones, technology & driving, 19 April 2021) [06/05/21] </a> who stipulate that all driver’s aids should be secured and not touched while driving.
           The device is recommended to be plugged in to charge to while the app is running, rather than drain the battery and to minimise disruptions. <a
            href="https://www.apple.com/au/shop/iphone/accessories/power-cables?fh=458e%2B45d4:"> (Power & Cables)
          [07/05/21]</a> When the app is further developed, the front facing camera will also monitor other fatigue cues such as yawning or dropping of the head.  </p>
      <p>The accelerometer and gyroscope will also be able to determine whether the driver is becoming tired by comparing the normal movements of a
         person when they are awake and comparing them with reduced movements which may indicate that they are fatigued so sleep may be imminent <a
            href="https://www.sleepfoundation.org/circadian-rhythm/sleep-drive-and-your-body-clock#:~:text=Because%20of%20our%20circadian%20rhythm,that%20can%20occur%20after%20lunchtime.">
          (Sleep Drive and Circadian Rhythm) [07/05/21] </a>This will trigger an alarm and the driver will need to vocally deactivate by saying “Hey
          Siri, deactivate”. Following deactivation, the driver will be advised to make a stop where safe to do so and play the reaction time game to establish
          whether they are alert enough to resume driving.

The functions of the app are to include monitoring biometrics through the Apple Watch.  Key to this is heart rate, which slows down when we relax, and in turn can indicate the onset of sleep. <a
            href="https://www.health.harvard.edu/blog/how-does-sleep-affect-your-heart-rate-2021012921846"> (How does
          sleep affect your heart rate? POSTED JANUARY 29, 2021) [07/05/21] )</a>. The watch monitors hand and arm movements indicating a relaxed
           driver which can indicate drowsiness.  Additionally, the gyroscope also determines the time the user has been awake and will enable the app
           to evaluate the fatigue level of the driver. Irrespective of the measurements taken, the app will alarm to have a rest after the standard of 2 hours as a precaution. <a
            href="https://www.tmr.qld.gov.au/Safety/Driver-guide/Driving-safely/Driving-tired.aspx#:~:text=take%20regular%20breaks%20%E2%80%93%20you%20should,spots%20and%20driver%20reviver%20stops">
          (Driving tired) [17/05/21]</a>
      </p>
      <p>The phone’s internal camera, along with the gyroscope, accelerometer, and the Apple watches heart rate monitor, will work together and
         gather data to predict a few scenarios. These are the drivers journey exceeding the time limit of 2 hours, a potential collision, and
         biometrics to predict fatigue cues. All these factors will then issue a warning in the form of an alarm. If the alarm is not verbally deactivated, <a
            href="https://www.vicroads.vic.gov.au/safety-and-road-rules/driver-safety/mobile-phones-and-driving">
          (Mobile phones, technology & driving, 19 April 2021) [06/05/21] </a>the emergency contact and emergency services will be notified
           of a potential collision. If the driver does deactivate the alarm, Drive Aware will prompt the driver to stop the vehicle. Then
           the Drive Aware app will suggest conducting the reaction test game described above.</p>
           <br>
           <h3>Future Plans </h3>
           <h5>EEG Monitoring </h5>
      <p>Further developments we have discussed to predict fatigue while driving include the use of an  <a
          href="https://www.neeuro.com/senzeband/"> EEG monitoring </a> device applied to the driver’s head.  These now exist in the
           form of a headband or cap <a href="https://www.youtube.com/watch?v=NO-iUU8PIcE"> (Neuroscience - Sleep Cycle EEG, Jul 18,
          2016) [06/05/21] </a>. This would allow a more accurate reading, measuring the point at which a driver may enter different
           stages of the wake-sleep state. It was suggested that not all smart phone users have smart watches but would still benefits
            from the accessibility and affordability of using this app compared to the inbuilt technology stated previously in assignment 2
             such as  “<a href="https://www.seeingmachines.com/"> Seeing Machines</a>” as an example. So, we believe that the small costs associated in purchasing these wearables to help determine a driver’s sleep state may be
      considered reasonable to users.  Hopefully this will create safer roads for the people we love.
    </p>
     <p>Though, in Assignment 2 we briefly touched on the EEG wearable bands for driver monitoring. While for Assignment 3 we felt
       extending the scope to include this would be too challenging, we believe developing a working prototype and linking it with the
       EEG band would be well worth considering. Gerard, a member of the DAT Team, contacted  <a
            href="https://www.neeuro.com/"> Neeuro</a>  a manufacturer of EEG headbands as they were looking for development partners.  This lead to a <a
            href="https://rmiteduau-my.sharepoint.com/personal/s3882545_student_rmit_edu_au/Documents/Microsoft%20Teams%20Chat%20Files/zoom_0%202.mp4">
          meeting</a> to discuss the Drive Aware app concept and the potential for collaboration with them. The meeting proved to
           be very promising and using their headband with the Drive Aware app appears perfectly feasible once it is developed.
           Their bands connect to mobile devices via  <a href="https://electronics.howstuffworks.com/bluetooth.htm">
          Bluetooth</a> for both iOS and <a href="https://developer.android.com/guide"> Android</a> which would work well with our
           initial Apple development and for future developments with Android. They also offer their own SDK for app developers
           to work with. The EEG band would assist in detecting fatigue levels by discovering whether the brain waves emitted are
            either Beta waves or Alpha waves.  <a href="https://www.nature.com/articles/npp2017294"> Neuronal Mechanisms for Sleep/Wake
          Regulation and Modulatory Drive, Published: 05 December 2017, [03/05/21] </a>
        Beta brain waves occur when a person is awake and alert. The Alpha brain waves occur when the person is
        awake but in a very relaxed state and falling asleep.<a href="https://www.youtube.com/watch?v=ycQ3DL5TX9U"> EEG
          Waveforms Building Blocks of Sleep Staging</a>
        We hope to be able to prevent any collision before it gets to the following stage of Theta brain waves which is
        the first stage of sleep as shown on the <a href="https://www.youtube.com/watch?v=v5DUPLI580g"> image below</a>
        to the left. An example of the wearable <a href="https://www.neeuro.com/senzeband/"> EEG head device</a> is to
        the right. <a href="https://www.youtube.com/watch?v=XMizSSOej0"> (Introduction to EEG, Aug 26, 2014)
          [06/05/21] </a>

      </p>
      <img alt="EEG head wear from neeuro image" class="img-fluid" src="assets/eeghead.png">
      <br>
      <h4>Terms and Conditions  </h4>
      <p>As with all systems, there are elements that could go wrong, such as the driver disobeying the app’s recommendations of
        driving after a failed test.  This could cause a collision. The user of the app should choose to apply all the rules to
         help keep them safe willingly and not go against recommended usage. To mitigate this, we decided it was necessary for
          the app to have terms and conditions even considered at this stage of development. Once the user opens the App and logs
          in, the user is required to agree to the terms and conditions of the app or they will be unable to make use of it.  </p>
          <br>
          <h4>Monitoring Circadian Rhythm </h4>
      <p>This app is appropriate for usage of a daily commuter driving to and from work, late nights, or early mornings.  However,
         when we are most tired it is likely to be of most use and this is often indicated
through our Circadian rhythm.  <a
            href="https://www.news-medical.net/health/Circadian-Rhythm.aspx"> What is the Circadian Rhythm? [Y.
          Smith]</a> <a href="https://laylasleep.com/what-is-circadian-rhythm/"> What is Circadian Rhythm (And Why Your
          Circadian Clock is Important)[Layla] </a> In future, the application will monitor its user’s circadian rhythm closely and
           calibrate warning thresholds accordingly.
      </p>
      <img alt="circadian rhythem chart" class="img-fluid" src="assets/circadiumrhytjhem.jpg">
      <br>
      <br>
<h4>Version Without Any Wearable Devices </h4>
      <p>Having started with the hand drawn sketch and progressing more into the functionality of the app, we considered the app
        operating with just the iPhone monitoring the eyes and head movements alone in the case that the user does not own an Apple
        Watch. Of course, this will not be as accurate, but the driver may still benefit from some of the app’s functions. While using
         the app in this way is not optimal, it will still give some readings and data will be taken to deliver some of the benefits
          of driver monitoring. </p>
          <h4>Progress</h4>
          <h6>To demonstrate current progress, the flow chart below was from Assignment 2. This showed how we believed the app would function:  </h6>
      <img alt="first flow chart from A2" class="img-fluid" src="assets/basicflowchart.png" >
<p>From this, we have progressed to a proof-of-concept prototype.  The images below show what would happen in the three different scenarios: a <a href="https://www.figma.com/proto/oHbpoQPlhnr8q0IQA7Urow/A3-Group16-CollisionAlert?node-id=34%3A15044&scaling=scale-down&page-id=0%3A1">crash event</a>, <a href="https://www.figma.com/proto/PElVCqW6VZulzhcW0FsVHM/A3-Group16-FatigueCuesAlert?node-id=339%3A172&scaling=scale-down&page-id=0%3A1">driver fatigue</a>, <a href="https://www.figma.com/proto/jl1EMnjhf6f2pBPxMF3znI/Drive-Aware---A3-Group16?node-id=0%3A790&scaling=scale-down&page-id=0%3A1">or prolonged period of driving </a> <a href="Artefacts.html">(See more in Artefacts)</a>. </p>
     <img src="assets/sreenshotfigma.png" alt="flow of figma prototype images" class="img-fluid" >
<h2 id="roles">Roles</h2>

      <p>
        The DAT Team decided not to assign specific roles to team members during the project. Our reasoning was that we
        as a group do not currently have the experience or knowledge to program an app of the complexity that we wish to
        achieve. We have instead decided to use our experience in other areas to develop a prototype of the app. Tasks
        have been assigned based on what experience or exposure, if any, each member has had to different roles that
        will assist the group in creating our prototype. In practice, this has worked well as the group has a varied
        background and skill set but have all been willing to work hard and accommodate the others. For example, Nicole
        has some experience using Figma, so she will take the lead on creating the wireframing for our prototype and
        with Lilyana keen to gain experience in this area she offered to spend time working with her. Chris has some
        experience with video editing so he will be responsible for editing our video presentation. Naturally, Matthew
        continued to work on the development of the Drive aware project during A2 and Gerard, having a healthcare
        background, researched information on which biometrics should be measured and how. Other tasks, such as creating
        our storyboard for the video presentation, are performed by the entire group, and refined as we figure out what
        will provide the best outcome for our project. In the case that we can’t reach a definitive resolution, we
        (usually Nicole) setup a poll in MS Teams and let democracy dictate our course of action.
      </p>

      <br>

      <h2 id="scope">Scope & Limits</h2><br><br>
      <h3>Phase 1 Scope – Assignment 3</h3><br>
      <h4><u>Summary for the Purposes of Defining Scope</u></h4>
      <br>
      <p>The application ‘Drive Aware’ that was chosen for Assignment 2 submission - <a
          href="https://s3903477.github.io/ITT-Assignment-2/Project_Idea.html"></a> has the following
        functionalities.<br>
        <br>There are 4 types of monitoring suggested in the application. Some can be tracked using the iPhone and some
        by the Apple Watch*. Accordingly, both are recommended assessment of fatigue.<br><br></p>
      <h4>Monitoring methods of driver</h4>
      <ul>
        <li>Monitor 1 – Speed (iPhone)</li>
        <li>Monitor 2 – Heart rate (Apple Watch)</li>
        <li>Monitor 3 – Movement/arm placement (Apple Watch)</li>
        <li>Monitor 4 – Visual/Facial cues (iPhone)</li>
      </ul>
      <p style="font-size: smaller;"><em>*As technology improves and more sensors are included in iPhones and Apple
        watch devices, the monitoring level can increase.
        See future development for more information.</em></p>

      <p>The alerts for each type of monitored outcome will differ with individual alert text and pathways. These are
        explained below.</p>

      <h4>Alert pathway</h4>
      <ul>
        <li>Alert to notify driver that there is concerning behaviour that may be impacting their ability to drive
          safely. Movement change, facial cue change, known fatigue signs, etc.
          Driver to use Siri voice command to deactivate to limit distraction.
        </li>
        <li>The scope of this project limits alerts for our Prototype to: Fatigue signs from long driving period to
          trigger a rest, danger signs that may indicate a collision and a general
          fatigue alert that advises the driver that they may no longer be focused.
        </li>
        <li>Each alert would expect a voice command to deactivate to prevent the need to touch the phone. If this alert
          is ignored, the emergency pathway is activated.
        </li>
        <li>Emergency pathway will notify emergency contacts of the GPS location with a message via SMS. Emergency
          services will also be called. (This pathway is already
          in place with Apple Health SOS pathway and not redeveloped for this application)
        </li>
      </ul>
      <br>

      <h4>Rest Management</h4>
      <ul>
        <li>Timer start – Vehicle in motion</li>
        <li>Monitoring of facial cues and movement, etc. will aid in the assessment that the driver may be fatigued.
          Machine learning algorithms will improve the assessment the more
          the application is used. Drivers can have individual driving limitations and therefore setting a specific time
          will not be as accurate.
        </li>
        <li>When driver has pulled over and starts the rest period, the 15 minute timer for rest period will start
          (profile settings can increase this time to personalise – not in scope
          for prototype but will be considered in future development)
        </li>
        <li>Response/reaction time test will commence after the rest timer is complete</li>
        <li>Should the driver not be able to perform the test accurately or within the allotted time then rest period
          will recommence
        </li>
        <li>On success of test, driver can continue the drive</li>
      </ul>
      <br>
      <h4><u>Scope</u></h4>

      <p>The scope for Assignment 3 will provide a more in-depth plan on how to bring the application to life as well as
        a prototype for demonstration.
        <br><br>
        The decision to use a prototype as opposed to programming an Apple application was made due to time constraints
        and level of expertise in the Apple development area.
        <br> <br>
        A prototype will allow us to display our vision to prospective investors and be used for basic testing.</p>
      <br>
      <h4>Prototype to showcase the following: </h4>
      <br>
      <h5>New User Registration</h5>
      <ul>
        <li>Register email and password of new user</li>
        <li>Terms & Conditions</li>
        <li>Permission to access Apple Health data (heart rate, emergency contacts, etc.)</li>
        <li>Calibration required for app to collect baseline for facial cues</li>
      </ul>
      <br>
      <h5>Current User</h5>
      <ul>
        <li>Login using current email and password</li>
        <li>User to click on Start button when they commence their journey</li>
      </ul>
      <br>
      <h5>Reaction test after rest</h5>
      <ul>
        <li>Data collected and measured to test for signs of fatigue</li>
        <li>User alerted to start rest time</li>
        <li>Rest timer set to 15 minutes</li>
        <li>On conclusion of 15 minutes, user is requested to test their reaction/response time with a game</li>
        <li>If user succeeds – journey can continue</li>
        <li>If user does not succeed, rest timer is reset to 15 minutes again</li>
      </ul>
      <br>
      <h5>Collision alert</h5>
      <ul>
        <li>User is already logged in and journey has commenced</li>
        <li>Alert triggered in the event of rapid deceleration</li>
        <li>User alerted</li>
        <li>User to deactivate alert with voice command</li>
        <li>If alert is not deactivated, notifications sent to Emergency contacts</li>
      </ul>
      <br>

      <h5>Fatigue cues alert</h5>

      <ul>
        <li>User is already logged in and journey has commenced</li>
        <li>Data collected and measured to test for signs of fatigue (heart rate, movement, facial cues, etc.)</li>
        <li>User alerted</li>
        <li>User to deactivate alert with voice command</li>
        <li>If alert is not deactivated, second alert is sent</li>
        <li>If second alert is not deactivated then notifications sent to Emergency contacts</li>
      </ul>
      <br>
      <p>In order for the Prototype to flow in the intended way for demonstration, we have split the prototypes into 3
        links. More information can be found in <a href="Artefacts.html">artefacts.</a>
        <br>
        The scope of the project also extends to basic testing (see testing)</p>
      <br>
      <br>
      <h3>Phase 2 – Future Developments (Out of scope for Assignment 3)</h3>
      <br>

      <ul>
        <li>Prototype development is used to show the key functionalities and is not extended to all and every area we
          would develop

          <ul>
            <li>Examples of functions not displayed in Prototype – bottom menu icons

              <ul>
                <li>Profile menu – update user details, change password, calibration, logout</li>
                <li>Navigation – open in maps</li>
                <li>Activity – daily, weekly, monthly, etc. reporting on history of data collected from heart rate,
                  gyroscope, accelerometer, response time tests, etc.
                </li>
                <li>Settings - notification settings</li>
              </ul>
            </li>
          </ul>

          <ul>
            <li>Headband using electroencephalogram (EEG) monitoring of Beta and Alpha waves
              <ul>
                <li>The technology is available now but for the scope of the assignment we had to draw a line in the
                  sand.
                  We have reached out to We have reached out to the manufacturers of two devices:
                  <ul>
                    <li>BrainBit ('Wearable EEG headband" BrainBit', 2021)</li>
                    <li>Neuro ('SenzeBand: The Brainwave Sensor for Everyone', 2021) and were waiting on some further
                      information. Due to the time constraints, we felt this is a path for future research.
                    </li>
                  </ul>
                </li>
              </ul>
            </li>
          </ul>

          <ul>
            <li>Thermal Imaging
              <ul>
                <li>Technology that could be explored and provide benefit to the Project idea but not in scope due to
                  time
                  constraints
                </li>
              </ul>
            </li>
          </ul>

          <ul>
            <li>Integration with vehicle's in-built digital screen/navigation systems</li>
            <li>Android Application and Non-Apple Smart Watch expansion</li>
            <li>Expansion of reporting based on the data collected
              <ul>
                <li>Initial reporting is limited to activity and rest game response time</li>
                <li>Further statistical reporting can be developed based on the collection of data</li>
              </ul>
            </li>
            <li>Rest game improvements
              <ul>
                <li>Initial game is very basic and only has left and right test to show functionality</li>
                <li>Future games can be developed with improvement on graphics and objects to test reaction times.
                  For example, the user could touch a car image when it appears and not to touch pedestrian. Failure to
                  react to the correct
                  object could be used to measure reaction ability and speed
                </li>
              </ul>
            </li>
            <li>Partnership with Insurance companies and a reward system that could be investigated. Driver could gain
              points and receive bonuses or improved insurance rates to encourage the use of this application. Insurance
              companies have used applications to encourage safe driving in this way in the past (Baker 2016)
            </li>
          </ul>
        </li>
      </ul>


      <br>

      <h2 id="tools">Tools & Technologies</h2>
      <br>
<h4>Overview</h4>
      <p>The tools and technologies we would need to possess to develop the Drive Aware app on an iOS are outlined below.  Firstly,
         the <a href="https://developer.apple.com/xcode/features/"> XCode developmental tool</a>,
         this is the platform on which we would write our code using the <a href="https://docs.swift.org/swift-book/"> Swift
          Programming Language (Swift 5.4)</a> and build our user interface (UI). We would require database
        development to be able to store the user’s details and data gathered. This could be done with <a
            href="https://nordicapis.com/what-is-the-difference-between-an-api-and-an-sdk/"> SDK (Software Development
          Kit) and API (Application Programming Interface)</a>. The SPC (software processing control) will allow us to
        input the user’s personal data and <a href="https://www.w3schools.com/whatis/whatis_cli.asp"> CLI (Command
          Line Interface) </a>allows the input of specific details. </p>
<br>
<h4>GUI</h4>
      <p>A <a href="https://apple.fandom.com/wiki/Graphical_user_interface"> GUI- graphical user interface</a> will
        allow the reaction time game to function and <a
            href="https://developer.apple.com/documentation/xcode/allowing-apps-and-websites-to-link-to-your-content">
          URI- universal resource identifiers </a> URI- universal resource identifiers allows the app to call emergency services if required.
          If Drive Aware were to be a native app, it would offer a better UX- user experience by having quicker navigation and enhanced security
           of the user’s data. Also being a  <a
            href="https://www.webfx.com/blog/web-design/native-app-vs-mobile-web-app-comparison/"> native app</a>,
       will allow the camera to be accessed which in turn can be used to monitor the driver’s vital cues with the forward-facing lens.  </p>
<br>
<h4>Wearable Devices</h4>
      <p>While beyond the scope of Assignment 3, as suggested in A2 (Assignment 2), the use an <a href="https://www.healthline.com/health/eeg"> EEG
        (Electroencephalography) </a>wearable device, would help monitor if sleep were to occur by measuring the electrical signals of the brain.
         The waves that the EEG band will discover when a person is alert are <a
            href="https://www.sciencedirect.com/topics/medicine-and-dentistry/beta-wave"> Beta waves</a>. When a person is in a tired and almost
             falling asleep state, the EEG shows <a
            href="https://www.healthline.com/health/alpha-brain-waves"> Alpha waves</a>. This in conjunction with the
        <a ref="https://support.apple.com/en-au/guide/watch/apd0d5d452ce/watchos"> Apple Watch and iPhone measuring
          the biometrics</a> would provide a more accurate reading and perception of whether the driver is showing signs of drowsiness or
          imminent sleep. The EEG is a very promising future addition but at this stage, while we are exploring the benefits, we want to
           keep the initial operation simple. Accordingly, we will not be including this wearable technology in the first working prototype.  </p>

      <img alt="apple watch and iphone" class="img-fluid" src="assets/newphoneimage.jpg">
<br>
<br>
<h4> Aesthetics </h4>
      <p>We need to create icons for use in our app or alternatively we could use the <a href="https://freeiconshop.com/"> icon
        shop</a> which is open source for our user interface-UI. <a
          href="https://www.figma.com/files/recent?fuid=971228045439887774"> Figma </a>has been selected to develop our proof-of-concept
           prototype as one of our valued team members, Nicole Clarke, has experience using it. While not relevant to functionality, if we wanted to use <a
            href="https://developer.apple.com/fonts/"> Apple fonts</a>, we would require purchasing a licence.</p>

            <br>
            <h4>Hardware </h4>
            <p>To create
             an Apple iOS app, one can use any Mac device and install the XCode programme which uses the swift coding language.
             We would need an Apple mac to work on for the <a
            href="https://www.macrumors.com/roundup/ios-14/"> iOS</a>version and have it updated to version iOS 14. An
            iPhone 6 and above and Apple watch will also be needed to test the app, after the app is complete. Should it
            be decided to include the use of the EEG headband after the initial testing phase, an Apple Watch and the EEG
             headwear <a href="https://www.neeuro.com/senzeband/">
          Neeuro-SenzeBand</a>,, will be used together to create a more accurate reading. The headwear will work via <a
            href="https://electronics.howstuffworks.com/bluetooth.htm">Bluetooth</a> and operates on iOS and Android for
             future developments. In our case we are choosing Apple products to begin with. When creating the  <a
            href=”https://developer.android.com/”> Android </a> version<a href=”https://www.javascript.com/”> Java
          Script</a> will be used.  .  To summarise: iMac or MacBook will be used as the Software Developers interface to
           design and code the App. iPhone will be used to test the functionality of the App during the testing phase.
            The Apple Watch will be used to test the functionality of the App during the testing phase.  </p>
<br>
      <h5> Meeting with Neeuro SenzeBand - With Gerard </h5>

      <div class="container-fluid p-0">
        <img alt="gerards meeting with neero img" class="img-fluid" src="assets/GerardMeetingVeeuro.jpg">
        <video class="w-100" controls>
          <source src="./assets/Gerard_Interview.mp4" style="height: 200px; width: 200px;" type="video/mp4">
        </video>

      </div>
      <br>
      <br>
      <h4>The Team’s Related Technical Skills </h4>

      <p>One team member, Christopher Smith, has some experience in video editing with <a
          href="https://www.blackmagicdesign.com/au/products/davinciresolve/"> Davinci Resolve</a> and <a
          href="https://www.apple.com/au/imovie/"> iMovie</a> which will come in handy when we need to complete Assignment 5.
          He also has some experience with UI/UX app design. Furthermore, he has some experience with <a
            href="https://careerfoundry.com/en/blog/ux-design/the-difference-between-ux-and-ui-design-a-laymans-guide/">
          UI/UX </a>app design. Furthermore, he has some experience with  <a href="https://create-react-app.dev/"> React
          -Java Script framework</a> that makes cross platform smartphone apps. He also constructed most of a Minesweeper clone
           with a colleague in his past. Liljana has some experience with <a
            href="https://www.wix.com/"> WIX</a> in web design and photo editing using the <a
            href="https://apps.apple.com/au/app/adobe-lightroom-photo-editor/id878783582"> Lightroom app</a>.
      </p>

      <h4>The Apple technologies we would need are:</h4>
      <p>The native <a href="https://developer.apple.com/xcode/swiftui/"> Swift UI </a> (user interface) which is used
        for building Apple apps. The developer tools below are used and integrated through Swift. The <a
            href="https://developer.apple.com/machine-learning/create-ml/"> Create ML </a>machine learning tool, this will be
             used to train the app on how to recognise a driver yawning, the rate of blinking and attentiveness.
                <a href="https://developer.apple.com/documentation/coremotion"> Core Motion </a>reports motion from the
        accelerometers and gyroscopes, and from the pedometer, magnetometer, and barometer. <a
            href="https://developer.apple.com/documentation/corelocation"> Core Location </a>provides services that determine
             a device’s geographic location, altitude, and orientation used for GPS. User-facing notifications, communicate
              information to users of the app, regardless of whether the app is running on the user's device.
        <a href="https://developer.apple.com/documentation/pushkit"> The Push Kit framework</a> supports specialized
        notifications for updating your Watch OS (Operating System) complications.<a
            href="https://developer.apple.com/documentation/pushkit"> Push Kit </a>notifications launch the app and
        give it time to respond. Both Push Kit and User Notifications use the Apple Push Notification service (APNs)
        to deliver push notifications to the user device.
      </p>
      <br>
      <h4>Connectivity and Integration </h4>
      <p>As the system gathers information using various sensors on a device, <a
          href="https://developer.apple.com/documentation/sensorkit"> Sensor Kit</a> enables an app to access selected
        raw data, that the device obtains from a sensor <a href="https://developer.apple.com/documentation/healthkit">
          Health Kit</a> and provides a central repository for health and fitness data on an iPhone and Apple Watch.
        With the user’s permission, apps communicate with the Health Kit store to access and share their data. The <a
            href="https://developer.apple.com/documentation/systemconfiguration"> System Configuration</a> framework
        helps determine the reachability of the device, to see if the Wi-Fi or cell connectivity are active. The <a
            href="https://developer.apple.com/documentation/watchconnectivity"> Watch Connectivity framework</a>
        transfers data between iOS apps and the <a href="https://developer.apple.com/documentation/watchkit"> Watch
          Kit</a> extension of a paired Watch OS app. The Watch Kit framework provides the infrastructure including an
        extension that manages background tasks such as, extended runtime sessions and Siri intents which will operate
        with our vocal deactivation of alarms. </p>
      <p><a href="https://developer.apple.com/documentation/coreml"> Core ML </a>(Machine Learning) will be used to
        integrate machine learning models into our app. Apps use Core ML APIs (Application Programming Interfaces) and
        user data to make predictions, and to train or fine-tune models, all on the user’s device. This can help the
        drive Aware app operate more efficiently. </p>
      <p>In the event of a crash, the iPhones and Apple watches <a
          href="https://www.lifewire.com/iphone-gps-set-up-1683393"> GPS </a>can be used to help locate a driver if
        they have become separated from their vehicle. The <a
            href="https://developer.apple.com/documentation/coremotion/getting_raw_accelerometer_events">
          accelerometer </a>is used to measure the iPhones speed so then together with the <a
            href="https://developer.apple.com/documentation/coremotion/getting_raw_gyroscope_events"> Gyroscope</a>
  it can gatherer the Information to determine if a driver’s watch wearing arm is active for example holding on to the steering wheel.   </p>
      <p>These technologies will work together as follows: the<a href="https://support.apple.com/en-au/HT210571"> forward-facing camera</a> will be monitoring the
        driver's visual cues and in conjunction with the <a
            href="https://developer.apple.com/machine-learning/">AI</a>(Artificial Intelligence) technology of facial recognition and the wire
             frame will help determine whether the driver's facial expressions are showing signs of fatigue. This could be shown with yawning and
             slower eye movements. <a
            href="https://developer.apple.com/documentation/avfoundation/cameras_and_media_capture/avcam_building_a_camera_app">
          AV Cam</a> allows the App to capture photos with depth data and record video using the front and rear iPhone
        cameras. We believe this would help in getting the camera to detect visual cues. The <a
            href="https://support.apple.com/en-us/HT204666"> Apple Watch Heart Rate Monitor </a>will be used to
        monitor a driver’s heart rate while driving which will help determine the relaxed state of the user. <a
            href="https://developer.apple.com/documentation/healthkit"> Health Kit</a> provides a central repository
        for health and fitness data on iPhone and Apple Watch. With the user’s permission, apps communicate with the
        Health Kit store to access and share this data. The heart rate monitor reports to this and we would access the
        data from the Health Kit. </p>
      <br>
      <h4>Tools and Technologies coming together</h4>
      <p><a href="https://developer.apple.com/xcode/"> XCode</a> consists of a suite of tools, from creating your app
        to testing, optimizing, and submitting it to the <a href="https://www.apple.com/au/app-store/"> App Store</a>.<a
            href="https://www.makeuseof.com/tag/macbook-vs-imac/"> iMac or MacBook</a> will be used to design and code
        the App. <a href="https://developer.apple.com/swift/"> Swift </a> ensures your code is fast and efficient and
        safe for the user. iPhone and Apple watch will be used to test the functionality of the App during the testing
        phase. If we have access to the <a href="https://www.frontiersin.org/articles/10.3389/fninf.2020.553352/full">
          EEG head device</a> once the app has been created, we could also test to see if the accuracy is elevated. <a
            href="https://testflight.apple.com/"> TestFlight</a> makes it easy to invite users to test your apps and
        collect valuable feedback before releasing your apps on the App Store. You can invite up to 10,000 testers
        using just their email address or by sharing a public link. <a
            href="https://developer.apple.com/app-store-connect/api/"> The App Store Connect API</a> is a <a
            href="https://developer.apple.com/documentation/sign_in_with_apple"> REST API </a>that enables the
        automation of actions you take in App Store Connect. The App Store is a safe and trusted place for customers
        to discover apps, and a fantastic opportunity for developers to deliver apps and services across iPhone, iPad,
        Mac, Apple TV, and Apple Watch. </p>
<br>
      <h2 id="testing">Testing</h2>
      <br>

<h5>Proof-of-Concept Testing</h5>
<br>

<p>
  As the scope of this stage of the project is limited to the production of a proof-of-concept prototype rather than a working prototype,
   testing of the product will focus on user understanding and interaction.  There is not a specific target market for the application in
   terms of age, gender or cultural background so it follows that testing should be conducted on as wide a demographic as possible, excluding
    only those under the legal driving age.  Testing at this stage will remain relatively simple, the subjects will be asked to view the prototype
     and provide in indication of their understanding of what the product will do and what each screen that is displayed will do and from what they
      can see how they should navigate through the application.  The test
    subjects will also be asked whether they would consider using the application once developed and if so, under what conditions.  Testing
     can be considered successful at this stage if users are clear about what the application proposes to do, and they state that they would
      make use of the application.  The testing of the proof-of-concept prototype will also aim to ascertain whether subjects would consider
      paying for the use Drive Aware as this may help determine the way in which the application
   generates income. </p>
</p>
<br>
<h5>Survey Results</h5>
<br>
<p>
  A brief survey, developed to implement the above, was designed and team members requested that fiends and family complete it.
   The survey ascertained whether the participants understood the purpose of the application, how it would operate, whether they
    would use it and if they would consider paying for it.
</p>
  <img alt="survey format" class="img-fluid" src="assets/SurveyImage.png">
<br>
<br>
<p>Although the sample size was small and the participants were known to the team, the results of the survey were encouraging.
   100% of respondents suggested that they understood the problem that the application was aiming to solve and how it proposed to
    solve it.  Most participants indicated they would use the application, those that did not commented that they did not have any devices
    turned on while driving.  The survey suggests that 50% of people will consider paying for the application which may be useful when determining whether to
charge for the app, look for advertising income or attempt to align with an insurer or motoring association.
</p><br>
<img alt="survey results pie charts" class="img-fluid" src="assets/survey_result.jpg">
<br>
<h5>
Further Testing
</h5>
<br>
<p>
Additional testing, if feasible, should include the use of the Apple iWatch ascertain whether the discernible variations in
 heart rate at the onset of sleep(Ogilvie 2001) are observable using the watch.  This can be carried out independently of the
  direct prototype testing, asking subjects with the device to wear it when falling asleep and submit their heart rate data.
   Ideally, this would be done with an EEG in place to correlate the stage of sleep with the heart rate however this is not practical.
</p>

<p>
 After a working prototype is developed, testing can progress to an applied stage.  As with the proof-of-concept testing,
 as the application is being designed with all drivers in mind and accordingly, test users should be as varied as possible.
  Ideally, testing should include subjects who vary in age, ethnicity, weight, and gender.  Although no specific variation in
   the biometrics is being anticipated, variations may be observed either at this stage or while ascertaining the suitability
   of the iWatch’s heart rate monitor which would allow for design changes pre-launch.
</p>
<br>

      <h2 id="timeframe">Timeframe</h2>

      <table class="table table-dark">

        <thead>

        <tr>
          <th scope="col">Week#</th>
          <th scope="col">Chris</th>
          <th scope="col">Gerard</th>
          <th scope="col">Liljana</th>
          <th scope="col">Matt</th>
          <th scope="col">Nicole</th>
        </tr>

        </thead>

        <tbody>

        <!-- Week 1 -->

        <tr>
          <th scope="row">1</th>
          <td colspan="5">During this week the team familiarised themselves with brief for A3. After our Wednesday
            meeting we decided each team member would select two sections from the Project Plan & Overview to work on.
            These sections are detailed on the next row
            <br>
            Storyboard submission due end of week
          </td>
        </tr>

        <tr>
          <th scope="row">

          <td>
            Roles
            <br>
            <br>Timeframe
            <br>
            <br>Storyboard Contribution
          </td>

          <td>
            Testing
            <br>
            <br>Risks
            <br>
            <br>Storyboard Contribution
          </td>

          <td>
            Plan and Progress
            <br>
            <br>Tools & Technologies
            <br>
            <br>Storyboard Contribution
          </td>

          <td>
            Scope & Limits
            <br>
            <br>Group Processes & Communications
            <br>
            <br>Storyboard Contribution
          </td>

          <td>
            Overview
            <br>
            <br>Aims
            <br>
            <br>Storyboard Contribution
          </td>
        </tr>

        <!-- Week 2 -->

        <tr>
          <th scope="row">2</th>

          <td colspan="5">
            Define the screens required to generate a prototype in Figma or similar
            <br>
            <br>Prototype Design
            <br>
            <br>
            <ul>
              <li>UI/UX Design</li>
              <li>Wireframing</li>
            </ul>
            <br>
            Aiming to have 90% of Project Plan completed by start of week 2
          </td>
        </tr>

        <tr>
          <th scope="row">

          <td>
            Roles
            <br>
            <br>Review Liljana’s Tools & Technologies Contribution
            <br>
            <br>Timeframe
          </td>

          <td>
            Review Liljana’s Tools & Technologies Contribution
          </td>

          <td>
            Review Liljana’s Tools & Technologies Contribution
            <br>
            <br>UI/UX design
            <br>
            <br>Wireframing
          </td>

          <td>
            Review Liljana’s Tools & Technologies Contribution
            <br>
            <br>Team Profile
          </td>

          <td>
            Review Liljana’s Tools & Technologies Contribution
            <br>
            <br>Skills & Jobs
            <br>
            <br>UI/UX design
            <br>
            <br>Wireframing
          </td>

        </tr>

        <!-- Week 3 -->

        <tr>
          <th scope="row">3</th>
          <td colspan="5">
            Contribute to script and ideas for presentation video
          </td>
        </tr>

        <tr>
          <th scope="row">

          <td>
            Record Script for presentation
          </td>

          <td>
            Record Script for presentation
          </td>

          <td>
            Record Script for presentation
          </td>

          <td>
            Record Script for presentation
          </td>

          <td>
            Record Script for presentation
          </td>

        </tr>

        <!-- Week 4 -->

        <tr>
          <th scope="row">3</th>
          <td colspan="5">
            Rubric Fulfilment
            <ul>
              <li>Team Profile</li>
              <li>Tools</li>
              <li>Project Plan</li>
              <li>Skills & Jobs</li>
              <li>Artefacts</li>
              <li>Group Reflection</li>
              <li>Presentation</li>
            </ul>
          </td>
        </tr>

        <tr>
          <th scope="row">

          <td>
            Build Website
            <br>
            <br>Edit Presentation Video
          </td>

          <td>
            Write Script
            <br>
            <br>Review and edit A3 content
          </td>

          <td>
            Write Script
          </td>

          <td>
            Write Script
            <br>
            <br>UI/UX design
            <br>
            <br>Wireframing
          </td>

          <td>
            Write Script
          </td>

        </tr>

        <!-- Week 5 -->

        <tr>
          <th scope="row">3</th>
          <td colspan="5">
            Review Content and Prototype
            <br>
            <br>Create PDF for submission
            <br>
            <br>Feedback & Group Reflection
          </td>
        </tr>

        <tr>
          <th scope="row">

          <td>
            Edit Presentation Video
          </td>

          <td>
            Review and edit A3 content
          </td>

          <td></td>
          <td></td>
          <td></td>

        </tr>

        <!-- Week 6 -->

        <tr>
          <th scope="row">6</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
              <li>Backend</li>
            </ul>
          </td>
        </tr>

        <!-- Week 7 -->

        <tr>
          <th scope="row">7</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
              <li>Backend</li>
            </ul>
          </td>
        </tr>

        <!-- Week 8 -->

        <tr>
          <th scope="row">8</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
              <li>Backend</li>
            </ul>
          </td>
        </tr>

        <!-- Week 9 -->

        <tr>
          <th scope="row">9</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
              <li>Backend</li>
            </ul>
          </td>
        </tr>

        <!-- Week 10 -->

        <tr>
          <th scope="row">10</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
              <li>Backend</li>
            </ul>
          </td>
        </tr>

        <!-- Week 11 -->

        <tr>
          <th scope="row">11</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
              <li>Backend</li>
            </ul>
          </td>
        </tr>

        <!-- Week 12 -->

        <tr>
          <th scope="row">12</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
            </ul>
            Testing
          </td>
        </tr>

        <!-- Week 13 -->

        <tr>
          <th scope="row">13</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
            </ul>
            Testing
          </td>
        </tr>

        <!-- Week 14 -->

        <tr>
          <th scope="row">14</th>
          <td colspan="5">Development
            <ul>
              <li>Frontend</li>
            </ul>
            Testing
          </td>
        </tr>

        <!-- Week 15 -->

        <tr>
          <th scope="row">15</th>
          <td colspan="5">Launch App</td>
        </tr>

        </tbody>
      </table>

      <h2 id="risks">Risks</h2>
<br>
      <ul>
          <li>General risks associated with the development of applications of which no further detail is required</li>
      </ul>
      <br>
      <h5>Risks Associated with Development</h5>
      <ul>
          <li>That had drawn images in the initial development stage will undergo some detrimental alteration during their transfer to Figma.</li>
          <li>The groups anticipated use of Figma and associated difficulties.  In terms of active platform usage this is substantially negated by one of our group (Nicole) having used the platform previously however the risk remains that there will be accessibility issues with the facility during the period in which we intend to use it, and this remains beyond our control.  This is somewhat offset by the capture of screenshots demonstrating the prototype which have now been included in this document (see Plans and Progress)</li>
          <li>The group's lack of experience in using Swift(‘Swift - Apple Developer’ n.d.).  recruitment of a competent and experienced Swift programmer may be challenging as it is known to be an in demand language, in part because of the development of applications like the one proposed here that use the iWatch(Swanner 2017).  Encouragingly though, Swift is touted as being a programming language that is easy to learn (Taieb n.d.) and so the group may be able to contribute towards the programming themselves reducing the need for outsourcing of some elements</li>
      </ul>
      <br>
        <h5>Risks Associated with Testing and Usage</h5>

      <ul>
          <li>Mounting of the phone on the dashboard (Camera Position).  The ability of the user to position the phone in a way that the camera can monitor them and be held steady enough to be effective.  Whether or not this is achievable may only be known at a relatively advanced stage of testing and could well compromise the functionality of several of the applications planned features</li>
          <li>Mounting of the phone on the dashboard (Screen Position).  For the application to work, the phone will inevitably be visible to the driver which in itself could present a safety issue.</li>
          <li>The iWatch and whether its measurements are adequately accurate for our purposes.</li>
          <li>Related to the point above, national and local laws on mobile phone usage while driving may need to be considered.  For example, in India, drivers are permitted to use their mobile phone for navigation purposes only, any other application being open is illegal (Dash 2020).  Terms of use and a disclaimer will need to be written accordingly for the application’s testing and usage.   While professional advice would be sought on this before development beyond our current scope, a simplified terms of use has been drafted (see Appendix - 4) and included in the prototype.</li>
          <li>Storage of user data.  The application’s design will mean that significant user data is held and will need to be protected.  Furthermore, because the application will presumably have uptake outside Australia, the storage of data will need to be GDPR compliant.</li>
          <li>Uptake.  The possibility that the application will not be desirable to those that would benefit from its usage most.  This could be offset by marketing the application to insurers who may incentivise their customers to use it as some have with driving applications that reward safe driving in the past(Baker 2016)</li>
          <li>Additional monitoring and other wearable devices.  Compatibility, integration, and accuracy of any further devices that the application is developed to work with </li>
      </ul>
<br>
<br>

      <h2 id="group">Group Processes & Communications</h2>
      <p>For Assignment 2, we did have another team member who was unresponsive to not only Microsoft Teams
        communication but also to direct emails via Canvas. This was addressed by making Anthony our Teacher and David
        our Tutor aware. We also removed the member from Teams.
        <br><br>The remaining 5 members of the DAT Team are very proactive and communicative. This has made the
        coordination of both Assignment 2 and 3 projects successful.
        <br><br>All members have notifications on for the Microsoft Teams group and therefore are very responsive to
        chat discussions, meeting invites and requests.
        <br><br>As all team members have different responsibilities and commitments at different times of the day. We
        have found that it is not always convenient to chat at the same time. We have navigated this with all members
        putting in the effort to regularly check regularly the chats.
        <br><br>Our team has agreed to twice weekly meetings so even if we have been busy with other commitments all
        team members have made the effort to attend in most cases.
      </p>

    </div>

  </div>

</div>

<!-- Optional JavaScript; choose one of the two! -->

<!-- Option 1: Bootstrap Bundle with Popper -->
<script crossorigin="anonymous"
        integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4"
        src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js"></script>

<!-- Option 2: Separate Popper and Bootstrap JS -->
<!--
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js" integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.min.js" integrity="sha384-Atwg2Pkwv9vp0ygtn1JAojH0nYbwNJLPhwyoVbhoPwBhjQPR5VtM2+xf0Uwh9KtT" crossorigin="anonymous"></script>
-->

<script src="js/sidebars.js"></script>
</body>
</html>
