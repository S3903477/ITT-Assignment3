<!doctype html>
<html lang="en">
<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">

  <!-- Bootstrap Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">

  <!-- A3 CSS -->
  <link rel="stylesheet" type="text/css" href="css/A3.css">

  <!-- Bootstrap Sidebars -->
  <link rel="stylesheet" type="text/css" href="css/sidebars.css">

  <title>Project Description</title>
</head>

<body>

<!-- Sidebar Navigation -->

<div class="wrapper d-flex align-items-stretch">

  <nav class="p-4 bg-white side-nav">
    <a href="A3TOC.html" class="d-flex align-items-center pb-3 mb-3 link-dark text-decoration-none border-bottom">
      <span class="fs-5 fw-semibold">A3 Our IT Project</span>
    </a>

    <ul class="list-unstyled ps-0">

      <li class="mb-1">
        <a class="btn btn-toggle rounded collapsed" data-bs-toggle="collapse"
           data-bs-target="#tp-collapse" aria-expanded="false" role="button">
          Team Profile
        </a>
        <div class="collapse mx-3" id="tp-collapse">
          <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
            <li><a href="Team_Profile.html#chris" class="link-dark rounded">Chris</a></li>
            <li><a href="Team_Profile.html#gerard" class="link-dark rounded">Gerard</a></li>
            <li><a href="Team_Profile.html#liljana" class="link-dark rounded">Liljana</a></li>
            <li><a href="Team_Profile.html#nicole" class="link-dark rounded">Matthew</a></li>
            <li><a href="Team_Profile.html#matt" class="link-dark rounded">Nicole</a></li>
          </ul>
        </div>
      </li>

      <li class="mb-1">
        <a class="btn rounded collapsed" href="Tools.html" aria-expanded="false">
          Tools
        </a>
      </li>

      <li class="mb-1">
        <a class="btn btn-toggle rounded collapsed" data-bs-toggle="collapse"
           data-bs-target="#pd-collapse" aria-expanded="false">
          Project Description
        </a>
        <div class="collapse mx-3" id="pd-collapse">
          <ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small">
            <li><a href="Project_Description.html#overview" class="link-dark rounded">Overview</a></li>
            <li><a href="Project_Description.html#aims" class="link-dark rounded">Aims</a></li>
            <li><a href="Project_Description.html#plans" class="link-dark rounded">Plans & Progress</a></li>
            <li><a href="Project_Description.html#roles" class="link-dark rounded">Roles</a></li>
            <li><a href="Project_Description.html#scope" class="link-dark rounded">Scope & Limits</a></li>
            <li><a href="Project_Description.html#tools" class="link-dark rounded">Tools & Technologies</a></li>
            <li><a href="Project_Description.html#testing" class="link-dark rounded">Testing</a></li>
            <li><a href="Project_Description.html#timeframe" class="link-dark rounded">Timeframe</a></li>
            <li><a href="Project_Description.html#risks" class="link-dark rounded">Risks</a></li>
            <li><a href="Project_Description.html#group" class="link-dark rounded">Group Processes & <br> Communications</a>
            </li>
          </ul>
        </div>
      </li>

      <li class="mb-1">
        <a class="btn rounded collapsed" href="Skills&Jobs.html" aria-expanded="false">
          Skills & Jobs
        </a>
      </li>

      <li class="mb-1">
        <a class="btn rounded collapsed" href="Artefacts.html" aria-expanded="false">
          Artefacts
        </a>
      </li>

      <li class="mb-1">
        <a class="btn rounded collapsed" href="Group_Reflection.html" aria-expanded="false">
          Group Reflection
        </a>
      </li>
    </ul>

  </nav>

  <!-- CONTENT GOES HERE -->

  <div class="section">

    <div class="container-fluid p-0 hero-image">
      <h1 class="display-2 text-white text-center p-5">Project Description</h1>
    </div>

    <div class="pr-5">

       <h2 id="overview">Overview</h2>

<h4>Topic: </h4>
<p>Our project, “Drive Aware”, involves the development of an iOS app with a corresponding Watch OS app that will monitor the biometrics of vehicle drivers.  The hope is that in doing this the app will be able to alert them of the onset of fatigue caused by sustained periods of driving. The App will collect and analyse data from the various sensors built in since the Apple iPhone n11 and the Apple Watch 6. The front facing camera of the iPhone will be used to track and analyse the driver’s visual cues, searching for signs of driver fatigue. Using AI technology and deep learning, the Drive Aware App will be able to recognise and analyse visual cues such as changes in posture, blinking and yawning frequency.  The corresponding watch application will monitor heart rate and actigraphy which will be used in conjunction with other data to assess the driver’s likely level of vigilance.</p>

<p> Alert systems will be in place in the event of a crash or in the event a driver is unresponsive to requested actions. The Drive Aware App will have the ability designated contacts and ultimately emergency services in such situations. </p>
  
<h4> Motivation:  </h4>
<p> According to Budget Direct 1,195 people were killed in road-related deaths in 2019 (Insurance, Statistics and 2020, 2021).  This equates to over 3 people per day. 36% of fatal crashes occurred in major cities and single vehicle accidents made up just under 50% of fatal crashes. Thankfully, there has been a decrease in road deaths since 1970 largely attributed to stricter road safety laws, measures put in place by transit authorities and safer vehicle standards (Insurance, Statistics and 2020, 2021). However, it is our belief that a single preventable fatality on our roads is one too many and it is this belief that inspired the development of the Drive Aware App.  </p>

<p> Driver fatigue is ranked 4th out of the 5 most common causes of fatal vehicle accidents in Australia (‘Fatal Five’ Causes of Car Accidents in Australia, 2021) and is considered as dangerous as driving under the influence of alcohol and is much harder to detect than drunk driving with driver’s simply unaware of how their driving and cognitive abilities can be impaired when driving tired (Fisher et al. 2011).  The graph below illustrates this, clearly showing that self-reporting of fatigue is not adequately reliable.   Worryingly, research has also indicated that the standard two hour continuous driving limit is too high with people varying considerably in their safe limit and most showing considerably decreased concentration after 80 minutes (Ting et al. 2008). </p>

<img src="assets/awakevsasleep.jpg" class="rounded mx-auto d-block" alt="awakevsasleep">
<p class="small"><em> Edited Graph taken from “The Process of Falling Asleep” (Ogilvie 2001) showing the variation in active and passive response (Ogilvie 1984) in comparison to Hori’s 9 hypnagogic EEG stages with the simplified standard sleep scoring (Hori, Hayashi & Tanaka 1998) as well as self-reporting and heart rate changes (Pivik & Busby 1996).  For the purposes of this project, the heart rate changes in comparison to both self-reporting and active response times are particularly noteworthy. They demonstrate that drivers may be unaware of the decrease in their response time as tiredness progresses and that there may be alterations in heart rate before the driver is conscious that they have become fatigued</em>.  </p>

  
<h4> Landscape: </h4>
<p> It is no secret that our lives are increasingly reliant on modern technology.  With this feeding our urge for instant gratification and the way in which we quickly access news and other information changing due to ownership of mobile phones approaching 80% of the Australian population, (Australia: smartphone users 2017-2025 | Statista, 2021).  The way in which we interact with technology is changing.  Furthermore, the use of wearable devices is becoming commonplace meaning people are increasingly used to having their biometrics monitored (Granwal 2020).  Because of this, we believe there will be demand for an App which can track and monitor biometric vital signs associated with driver fatigue.  </p>
  
<p> The Drive Aware App will be incorporating some of the top 14 mobile trends as identified by Quicksprout (14 Mobile Trends That Are Dominating 2021, 2021).  </p>
  
<h5>These include:</h5>
<li>Facial movement analysis. The App will use and collect data to recognise driver fatigue cues by monitoring a driver’s face through the front facing iPhone camera.</li>
  
<li> Syncing wearable technology with mobile devices. The Drive Aware App is an iOS app supported by a Watch OS App. With data being collected from sensors within the Apple Watch.</li>
  
<li> Location based technology. GPS will be used to help locate drivers should they be involved in a crash or accident and may be incapacitated.</li>
 
<li> Artificial intelligence (AI). The Drive Aware App will be able to learn and then recognise a driver’s visual cues to determine if they are suffering from the effects of driver fatigue.</li>  
  
<li> By working on this project and by bringing it from theoretical stage to tangible results and towards a working prototype, the Drive Aware Tech Team hopes to show future employers how we, both as a team and as individuals, have developed our IT skills.  From researching technology and background information, evaluating how it can be incorporated and used successfully within the App to learning how to use development tools and technology.  Ultimately, we are proud to have taken the initial steps required to bring the Drive Aware App to market.</li>
<br>
 
      <h2 id="aims">Aims</h2>

      <h2 id="plans">Plans & Progress</h2>

      <p>
        The Drive Aware project started off as the Assignment 1 project Idea of Matthew Wotton: one of our team
        members. The original concept was to develop an application for a wearable device, the Apple Watch, and for the
        iPhone that would monitor drivers and alert them to signs of fatigue (Wotton 2021). This is a widely recognised
        problem for truck drivers, they work long hours which leads to exhaustion

        <a href="https://www.cannonlogistics.com.au/blog/fatigue-management-truck-drivers-need-know/"> (Fatigue
          Management: What Truck Drivers Need To Know) [07/05/21]</a>

        in turn creating a hazardous environment for other
        road users.

        <a href="https://www.bitre.gov.au/publications/ongoing/fatal_heavy_vehicle_crashes_quarterly ">(Fatal
          Heavy Vehicle Crashes Australia—Quarterly Bulletins) [07/05/21]
        </a>

        Our group quickly became fond of polls as
        a way of coming to decisions and after a look at all the group’s Assignment 1 projects, Nicole organised a poll
        to decide which one we would like to work on together with Matthew’s coming out on top.
      </p>

      <p>
        As commenced our research in Assignment 2, we received some valuable constructive criticism from Daniel,
        Waymo’s System Engineering Manager

        <a href="https://s3903477.github.io/ITT-Assignment-2/Interview.html">(Josevski
          2021). (Interviewing an IT Professional) [07/05/21] </a>

        Gerard conducted a literature review of scholarly articles relating to driver fatigue as well as the physiology and measurement of stages of the onset of sleep which concluded with recommendations on which biometrics may be worth measuring and why (See artefacts). This was re-enforced by research subsequently undertaken by Liljana (Samson, 2021).

        <a href="https://onlinelibrary.wiley.com/doi/10.1002/ajhb.23541"> (Taking the sleep lab to the field: Biometric
          techniques for quantifying sleep and circadian rhythms in humans, David R. Samson) [07/05/21]
        </a>

      </p>

      <p>
        After a team discussion, we decided our aim for the user market would be any vehicle driver, including
        professionals and everyday commuters.
        <a href="https://www.optalert.com/driver-fatigue-why-does-driving-make-you-tired/"> ( Driver fatigue: why does
          driving make you tired?) [07/05/21] ) </a>

        We also decided on, to begin with at least, having the application accessible on an iPhone in conjunction with an Apple Watch

        <a href="https://support.apple.com/en-au/guide/watch/apd99e3c6a68/watchos"> (Apple Watch User Guide)
          [07/05/21] </a>

        and in the future consider further developing it on Android with a corresponding smart watch.
        This would not restrict the user market in the long term and issues would be identified on a single platform
        rather than needing to alter its construction to accommodate both Android and iOS. Additionally, we believe that
        starting with Apple for our prototype will be simpler as two of our team members have Apple Watches and
        understand their use and functionality.

        <a href="https://support.apple.com/en-au/guide/watch/apd99e3c6a68/watchos">(Apple Watch User Guide)
          [07/05/21] </a>
      </p>

      <br>
      <h3>The Drive Aware App Plan </h3>
      <h4>Hand drawn flow chart drafts. </h4>
      <img src="assets/handdrawnflow.png" alt="hand drawn flow charts">
      <br>
      <p>We started off with a hand drawn sketch outlining basic functionality, indicating how the app should look when
        opened including pop ups allowing the accessibility of data gathered from the Health App and available on the
        iPhone. After some discussion and research, we decided that this should then be followed by a prototype
        developed with Figma.<a href="https://www.figma.com/"> (Minds meeting minds is how great ideas meet the world)
          [07/05/21] </a> The prototype will allow us to show our vision and enable us to present the idea to others.
      </p>
      <p>The group believe that the components needed for the application’s operation should be easily accessible
        wearable smart technology and, initially at least, devices that the user currently owns. This enables the app to
        be interchanged to any vehicle as the equipment needed is neither cumbersome or inbuilt. This enables mobility
        and flexibility, also affordability compared to some similar technologies currently available offering driver
        monitoring such as Seeing Machines <a
            href="https://www.proactiveinvestors.co.uk/companies/news/213919/seeing-machines-sees-bright-future-for-driver-monitoring-technology-213919.html">
          (Seeing Machines sees bright future for driver monitoring technology) [07/05/21] </a></p>
      <h4>Flow charts created by team members are below. (See more in Artefacts)</h4>
      <img src="assets/otherflowcharts.png" alt="more flow charts from group members">
      <p>The images above show the multiple rough drafts show the progress of the flow of the prototype before we
        started using<a href="https://www.figma.com/"> Figma</a>. Among other things, we had inspiration for the visual
        aspects of the activity of the biometrics, from looking at the health app on one of our iPhones. This inspired
        us to display daily statistics and have a line graph showing the length of the drive with the biometric levels.
        This information can also be displayed as weekly statistics showing a comparison of the wakefulness throughout
        the week. Once the app has the user details and you are logged in, we have decided to add an extra screen for
        users to agree to the<a href="https://www.termsfeed.com/blog/5-reasons-need-terms-conditions/"> terms and
          conditions</a>. This was a result of assessing the risks associated with the application’s use as well as to
        limit liability (see Risks). Should user not agree to the terms: Drive Aware will not be available to assist
        them. After this, when the user presses start, the screen will go back to the user’s normal home screen and will
        have an indicator icon showing that the app is operating, this has been designed this way to minimise driver
        distraction. Another example of a function operating this way is the “personal hotspot” which, when one clicks
        on the menu section. The Data history will be stored in the app and will use the current technology used with
        the health app to gather and translate the user’s data. In the set-up stage of the Drive Aware App, the user
        will need to allow access to the <a href="https://www.apple.com › au › ios › health"> Health App</a> which will
        also allow access to the <a href="https://support.apple.com/en-us/HT207021"> Medical ID </a> which consists of
        the biometrics and emergency contacts. </p>
      <h4>Inspiration from the Health App </h4>
      <br>
      <img src="assets/inspofromhealth.png" alt="inspo from health app">
      <br>
      <br>
      <p>The group proposes to use a similar technology to the facial recognition technology currently in smart phones
        such as the wire frame to determine the user’s facial distinctions. <a
            href="https://support.apple.com/en-au/HT208108"> (About Face ID advanced technology) [07/05/21]</a> This
        will also allow the app to perceive the eyes as they appear when opened, to then be able to monitor the drivers
        eye movements when the app is in use and to enable warnings when there is a detection of fatigue occurring. This
        will also be in the initial use of the app in the set-up stage of the Drive Aware App, the user will need to
        allow access to the Health App which includes access to Medical ID including biometrics and emergency contacts.
      </p>
      <br>
      <h4>The Reaction Test Game</h4>
      <br>
      <p>The reaction test game was proposed as a solution to the problems caused by drivers lack of insight into their
        own fatigue levels (Ting et al. 2008). The original game involved colour selection time to ascertain reaction
        time (see image below). After some thought we have considered that we would run into some obstacles with the
        reaction test Game. We thought by changing it from the assorted colours on the pallet we initially had in A2, to
        something more shape based as the colour palette are too similar to one another and might confuse some users if
        they cannot identify the correct shade stated. It would especially not work well for colour blind people. <a
            href="https://www.healthline.com/health/eye-health/what-do-colorblind-people-see#:~:text=Color%20blindness%20is%20usually%20an,differentiate%20among%20shades%20of%20colors.&text=Research%20suggests%20that%20color%20blindness,yellow%2C%20and%20complete%20color%20blindness.">
          (What Do Colour blind People See?) [07/05/21] </a>
        So, the game we thought of starting with, to get an idea of a reaction time assessment to measure the fatigue
        level of the driver, was a considerably basic concept. You will be asked to click the left or right arrow when
        prompted. The questions will repeat three times and if the test is failed by the driver, then they will be
        required to rest for a further 15 mins with a timer being activated and followed by a retest of the game.
      </p>
      <img src="assets/reactiongame.png" alt="game concept images">
      <br>
      <br>
      <p>We will reconsider the contents of the game and make it more complex as the app progresses to future
        developments, but we have agreed for the prototype to operate in this way for now. We decided to steer away from
        the colour palate option and use arrows for our prototype and we can reassess having a simulator or something
        along those lines for future developments, to assess the alertness of the driver. </p>
      <h4>Some ideas we considered for the UI before we completed our prototype. </h4>
      <img src="assets/figmatemplate.png" alt="userinterface plan images">
      <br>
      <br>
      <ol>
        <li> Showing the control centre icon is in operation.
        </li>
        <li> Facial recognition technology
        </li>
        <li> Map’s location-accelerometer and gyroscope
        </li>
        <li> Contacts enabled to contact emergency services or person in an emergency.
        </li>
        <li> Home screen when the app is in use will appear like this but with icon on the top bar to indicate its
          operating.
        </li>
        <li> Voice deactivation screen with Siri as an example.
        </li>
        <li> The main screen in the app will be the same image we used for our banner in A2 without the avatars as it
          really does suit the concept of our app, having the roads and graphs which indicate measuring of data.
        </li>
      </ol>
      <p><a href="https://www.figma.com"> Figma templates [07/05/21]</a></p>
      <br>
      <p>The application will run in the background on the device once it has been activated and then will continue to
        operate through the smart watch measuring the biometrics <a
            href="https://onlinelibrary.wiley.com/doi/10.1002/ajhb.23541"> (Taking the sleep lab to the field: Biometric
          techniques for quantifying sleep and circadian rhythms in humans, David R. Samson) [07/05/21] </a> preventing
        the iPhone or Apple watch to be of a distraction to the driver. We thought of having a coloured indicator, green
        as an example, at the top of the screen indicating that the app is in fact operating and not a distraction. The
        iPhone should be securely mounted on the dashboard in sight of the driver’s eyes to enable the forward-facing
        camera function to detect the eye movements. It will monitor the length of time you have closed your eyes, for
        example, a blink. This can indicate whether your eyes are becoming tired. Having an extended blink can indicate
        fatigue and in turn have hazardous effects, therefore predicting sleep. This is also recommended by Vic Roads <a
            href="https://www.vicroads.vic.gov.au/safety-and-road-rules/driver-safety/mobile-phones-and-driving">(Mobile
          phones, technology & driving, 19 April 2021) [06/05/21] </a> that all driver’s aids should be secured and not
        touched while driving. The device is recommended to be plugged into an appropriate input for charging to suit
        the device, as the battery should be obtained to continue to operate.<a
            href="https://www.apple.com/au/shop/iphone/accessories/power-cables?fh=458e%2B45d4:"> (Power & Cables)
          [07/05/21]</a> The front facing camera will also monitor other fatigue cues such as yawning or dropping of the
        head. </p>
      <p>The accelerometer and gyroscope will also be able to determine whether the driver is becoming tired by
        comparing the normal movements of a person when they are awake and will be able to predict that their reduced
        movements which may indicate that they are fatigued and if sleep is imminent. <a
            href="https://www.sleepfoundation.org/circadian-rhythm/sleep-drive-and-your-body-clock#:~:text=Because%20of%20our%20circadian%20rhythm,that%20can%20occur%20after%20lunchtime.">
          (Sleep Drive and Circadian Rhythm) [07/05/21] </a>This will set the alarm and the driver should vocally
        deactivate the alarm by saying, “Hey Siri, Stop the Alarm”. Following the deactivation, the driver will be
        advised to make a stop where safe to do so and perform a short game to signify whether they are alert enough to
        then resume driving. The functions of the app that will be monitoring the biometrics through the Apple Watch,
        including heart rate, which slows down when we relax, and in turn can indicate the onset of sleep. <a
            href="https://www.health.harvard.edu/blog/how-does-sleep-affect-your-heart-rate-2021012921846"> (How does
          sleep affect your heart rate? POSTED JANUARY 29, 2021) [07/05/21] )</a>. It also monitors hand and arm
        movements indicating a relaxed driver so, therefore, can also predict drowsiness. The gyroscope can also predict
        the amount of time the user has been awake and so this together with the app can have a good evaluation of the
        fatigue level of the driver. If the user has been driving for a prolonged period, the app will alarm to have a
        rest after 2 hours as a precaution.<a
            href="https://www.tmr.qld.gov.au/Safety/Driver-guide/Driving-safely/Driving-tired.aspx#:~:text=take%20regular%20breaks%20%E2%80%93%20you%20should,spots%20and%20driver%20reviver%20stops">
          Driving tired [17/05/21]</a>
      </p>
      <p>The phone’s internal camera, along with the gyroscope, accelerometer, and the Apple watches heart rate monitor,
        will all work together and gather the data to best predict a few different scenarios. The drivers journey
        exceeding the time limit of 2 hours, may have potential collision and biometrics to predict Fatigue cues. All
        these factors will then issue a warning in the form of an alarm. If the alarm is not verbally deactivated, <a
            href="https://www.vicroads.vic.gov.au/safety-and-road-rules/driver-safety/mobile-phones-and-driving">
          (Mobile phones, technology & driving, 19 April 2021) [06/05/21] </a> the emergency contact and emergency
        services will be notified of a potential collision. If the driver does deactivate the alarm, Drive Aware will
        prompt the driver to stop the vehicle. Then the Drive Aware app will suggest conducting the reaction test game
        to measure the attention and concentration level of the driver by the speed of the reaction to the questions
        stated. It will require a fast response to the questions stated, and if the test is failed, it would require
        another 15-minute break and a repeat of the test, to determine if the driver is alert enough to then resume
        driving.</p>
      <p>Further developments we have discussed to predict fatigue while driving is an <a href="https://www.neeuro.com/senzeband/"> EEG monitoring </a> device applied to the driver’s head, in the form of a headband. <a href="https://www.youtube.com/watch?v=NO-iUU8PIcE"> (Neuroscience - Sleep Cycle EEG, Jul 18, 2016) [06/05/21] </a> This could promote more of an accurate reading in measuring a warning to the driver entering fatigue. It was suggested that not all smart phone users have smart watches but would still benefit from the accessibility and affordability of using this app compared to the inbuilt technology stated previously in assignment 2 from “<a href="https://www.seeingmachines.com/"> Seeing Machines</a>” as an example. So, we believe that the small costs associated in purchasing these wearables to help determine a driver’s alertness is justified, to create safer roads for the people we love. Though, in Assignment 2 we briefly touched on the EEG wearable bands for driver monitoring, but for Assignment 3 we believe to obtain a working prototype and linking it with the EEG band would be better left for future development. These EEG bands are highly feasible for the future production but are currently out of our time scope. Gerard, a member of the DAT Team, contacted <a href="https://www.neeuro.com/"> Neeuro</a> as they were looking for collaborators and had a <a href="https://rmiteduau-my.sharepoint.com/personal/s3882545_student_rmit_edu_au/Documents/Microsoft%20Teams%20Chat%20Files/zoom_0%202.mp4"> meeting</a> discussing the potential future of the Drive Aware app collaboration with them. The meeting proved to be very promising, and it seems the technology behind these wearable bands are feasible when our app is developed. They offer their bands to be used via <a href="https://electronics.howstuffworks.com/bluetooth.htm"> Bluetooth</a> with iOS and <a href="https://developer.android.com/guide"> Android</a> which will support Apple and future developments with Android. They also offer their own SDK to use with the wearable device. The EEG band would assist in detecting fatigue levels by discovering whether the brain waves emitted are either Beta waves or Alpha waves.<a href="https://www.nature.com/articles/npp2017294"> Neuronal Mechanisms for Sleep/Wake Regulation and Modulatory Drive, Published: 05 December 2017, [03/05/21] </a> 
The Beta brain waves occur when a person is awake and alert. The Alpha brain waves occur when the person is awake but in a very relaxed state and falling asleep.<a href="https://www.youtube.com/watch?v=ycQ3DL5TX9U">  EEG Waveforms Building Blocks of Sleep Staging</a>
 We hope to be able to prevent any collision before it gets to the following stage of Theta brain waves which is the first stage of sleep as shown on the <a href="https://www.youtube.com/watch?v=v5DUPLI580g"> image below</a> to the left. An example of the wearable <a href="https://www.neeuro.com/senzeband/"> EEG head device</a> is to the right. <a href="https://www.youtube.com/watch?v=XMizSSOej0"> (Introduction to EEG, Aug 26, 2014) [06/05/21] </a>

      </p>
      <img src="assets/eeghead.png" alt="EEG head wear from neeuro image">
      <p>There are some elements that could go wrong, such as, if the driver disobeys the apps recommendations of
        driving after a failed test, then this could potentially cause a collision. The user of the app should choose to
        apply all the rules to help keep them safe willingly and not go against the recommended usage, as it could cause
        serious or fatal collision as trucks in specific are exceptionally large and heavy, taking up a lot of space on
        our roads. In saying this, we decided it was necessary for the app to have terms and conditions. So once the
        user opens the App and logs in, the user should agree to the terms and conditions in obeying the recommended
        instructions of the Drive Aware app, to then be able to proceed with its functioning. </p>
      <p>This app is also appropriate for usage of a daily commuter driving to and from work, late nights, or early
        mornings, when we are most tired which is shown through our Circadian rhythm. <a
            href="https://www.news-medical.net/health/Circadian-Rhythm.aspx"> What is the Circadian Rhythm? [Y.
          Smith]</a> <a href="https://laylasleep.com/what-is-circadian-rhythm/"> What is Circadian Rhythm (And Why Your
          Circadian Clock is Important)[Layla] </a> <a
            href="https://www.saltwire.com/newfoundland-labrador/wheels/circadian-rhythm-plays-vital-role-in-driving-245554/">
          Circadian rhythm plays vital role in driving
          Richard Russell </a> The drive can become relaxed and if there is no stimulus the driver can become drowsy and
        in turn cause fatal consequences.
      </p>
      <img src="assets/circadiumrhytjhem.jpg" alt="circadian rhythem chart" width="730" height="500">
      <br>
      <br>
      <p>It is well established that as a driver becomes relaxed during monotonous driving and when there is no stimulus
        the driver will become drowsy which can have fatal consequences(Fisher et al. 2011). Because of this, another
        potential user of Drive Aware may be holiday makers on long road trips with their families, especially now with
        covid 19 putting severe restrictions on overseas travel <a
            href="https://covid19.homeaffairs.gov.au/leaving-australia"> (COVID-19 and the border Leaving Australia)
          [07/05/21] </a>This has allowed families to travel more within our country and even using caravans more, <a
            href="https://www.vicroads.vic.gov.au/safety-and-road-rules/vehicle-safety/safe-caravanning"> (Safe
          caravanning) [07/05/21]</a> which are large and can be dangerous if the driver is not fully alert. Sadly,
        these situations are possible and can have severe consequences so, the drive aware app would be beneficial to
        these drivers too, and not just the professional driver. </p>
      <p>Having started with the hand drawn sketch and progressing more into the functionality of the app, we considered
        the app operating with just the iPhone monitoring the eyes and head movements alone in the case that the user
        does not own an Apple Watch. Of course, this will not be as accurate, but the driver may still benefit from some
        of the app’s functions. While using the app in this way is not optimal, it will still give some readings and
        data will be taken to deliver some results for driver monitoring. The flow chart below is from Assignment 2
        showing how we believed the app would function. </p>
      <img src="assets/basicflowchart.png" alt="first flow chart from A2" width="460" height="460">

      <h2 id="roles">Roles</h2>
      <br>
      <br>
      <br>

      <h2 id="scope">Scope & Limits</h2><br><br>
      <h3>Phase 1 Scope – Assignment 3</h3><br>
      <h4><u>Summary for the Purposes of Defining Scope</u></h4>
      <br>
      <p>The application ‘Drive Aware’ that was chosen for Assignment 2 submission - <a
          href="https://s3903477.github.io/ITT-Assignment-2/Project_Idea.html"></a> has the following
        functionalities.<br>
        <br>There are 4 types of monitoring suggested in the application. Some can be tracked using the iPhone and some
        by the Apple Watch*. Accordingly, both are recommended assessment of fatigue.<br><br></p>
      <h4>Monitoring methods of driver</h4>
      <ul>
        <li>Monitor 1 – Speed (iPhone)</li>
        <li>Monitor 2 – Heart rate (Apple Watch)</li>
        <li>Monitor 3 – Movement/arm placement (Apple Watch)</li>
        <li>Monitor 4 – Visual/Facial cues (iPhone)</li>
      </ul>
      <p style="font-size: smaller;"><em>*As technology improves and more sensors are included in iPhones and Apple
        watch devices, the monitoring level can increase.
        See future development for more information.</em></p>

      <p>The alerts for each type of monitored outcome will differ with individual alert text and pathways. These are
        explained below.</p>

      <h4>Alert pathway</h4>
      <ul>
        <li>Alert to notify driver that there is concerning behaviour that may be impacting their ability to drive
          safely. Movement change, facial cue change, known fatigue signs, etc.
          Driver to use Siri voice command to deactivate to limit distraction.
        </li>
        <li>The scope of this project limits alerts for our Prototype to: Fatigue signs from long driving period to
          trigger a rest, danger signs that may indicate a collision and a general
          fatigue alert that advises the driver that they may no longer be focused.
        </li>
        <li>Each alert would expect a voice command to deactivate to prevent the need to touch the phone. If this alert
          is ignored, the emergency pathway is activated.
        </li>
        <li>Emergency pathway will notify emergency contacts of the GPS location with a message via SMS. Emergency
          services will also be called. (This pathway is already
          in place with Apple Health SOS pathway and not redeveloped for this application)
        </li>
      </ul>
      <br>

      <h4>Rest Management</h4>
      <ul>
        <li>Timer start – Vehicle in motion</li>
        <li>Monitoring of facial cues and movement, etc. will aid in the assessment that the driver may be fatigued.
          Machine learning algorithms will improve the assessment the more
          the application is used. Drivers can have individual driving limitations and therefore setting a specific time
          will not be as accurate.
        </li>
        <li>When driver has pulled over and starts the rest period, the 15 minute timer for rest period will start
          (profile settings can increase this time to personalise – not in scope
          for prototype but will be considered in future development)
        </li>
        <li>Response/reaction time test will commence after the rest timer is complete</li>
        <li>Should the driver not be able to perform the test accurately or within the allotted time then rest period
          will recommence
        </li>
        <li>On success of test, driver can continue the drive</li>
      </ul>
      <br>
      <h4><u>Scope</u></h4>

      <p>The scope for Assignment 3 will provide a more in-depth plan on how to bring the application to life as well as
        a prototype for demonstration.
        <br><br>
        The decision to use a prototype as opposed to programming an Apple application was made due to time constraints
        and level of expertise in the Apple development area.
        <br> <br>
        A prototype will allow us to display our vision to prospective investors and be used for basic testing.</p>
      <br>
      <h4>Prototype to showcase the following: </h4>
      <br>
      <h5>New User Registration</h5>
      <ul>
        <li>Register email and password of new user</li>
        <li>Terms & Conditions</li>
        <li>Permission to access Apple Health data (heart rate, emergency contacts, etc.)</li>
        <li>Calibration required for app to collect baseline for facial cues</li>
      </ul>
      <br>
      <h5>Current User</h5>
      <ul>
        <li>Login using current email and password</li>
        <li>User to click on Start button when they commence their journey</li>
      </ul>
      <br>
      <h5>Reaction test after rest</h5>
      <ul>
        <li>Data collected and measured to test for signs of fatigue</li>
        <li>User alerted to start rest time</li>
        <li>Rest timer set to 15 minutes</li>
        <li>On conclusion of 15 minutes, user is requested to test their reaction/response time with a game</li>
        <li>If user succeeds – journey can continue</li>
        <li>If user does not succeed, rest timer is reset to 15 minutes again</li>
      </ul>
      <br>
      <h5>Collision alert</h5>
      <ul>
        <li>User is already logged in and journey has commenced</li>
        <li>Alert triggered in the event of rapid deceleration</li>
        <li>User alerted</li>
        <li>User to deactivate alert with voice command</li>
        <li>If alert is not deactivated, notifications sent to Emergency contacts</li>
      </ul>
      <br>

      <h5>Fatigue cues alert</h5>
      <ul>
        <li>User is already logged in and journey has commenced</li>
        <li>Data collected and measured to test for signs of fatigue (heart rate, movement, facial cues, etc.)</li>
        <li>User alerted</li>
        <li>User to deactivate alert with voice command</li>
        <li>If alert is not deactivated, second alert is sent</li>
        <li>If second alert is not deactivated then notifications sent to Emergency contacts</li>
      </ul>
      <br>
      <p>In order for the Prototype to flow in the intended way for demonstration, we have split the prototypes into 3
        links. More information can be found in <a href="Artefacts.html">artefacts.</a>
        <br>
        The scope of the project also extends to basic testing (see testing)</p>
      <br>
      <br>
      <h3>Phase 2 – Future Developments (Out of scope for Assignment 3)</h3>
      <br>
      <ul>
        <li>Prototype development is used to show the key functionalities and is not extended to all and every area we
          would develop
        </li>
        <ul>
          <li>Examples of functions not displayed in Prototype – bottom menu icons</li>
          <ul>
            <li>Profile menu – update user details, change password, calibration, logout</li>
            <li>Navigation – open in maps</li>
            <li>Activity – daily, weekly, monthly, etc. reporting on history of data collected from heart rate,
              gyroscope, accelerometer, response time tests, etc.
            </li>
            <li>Settings - notification settings</li>
          </ul>
        </ul>
        <ul>
          <li>Headband using electroencephalogram (EEG) monitoring of Beta and Alpha waves</li>
          <ul>
            <li>The technology is available now but for the scope of the assignment we had to draw a line in the sand.
              We have reached out to We have reached out to the manufacturers of two devices:
            </li>
            <ul>
              <li>BrainBit ('Wearable EEG headband" BrainBit', 2021)</li>
              <li>Neuro ('SenzeBand: The Brainwave Sensor for Everyone', 2021) and were waiting on some further
                information. Due to the time constraints, we felt this is a path for future research.
              </li>
            </ul>
          </ul>
        </ul>
        <ul>
          <li>Thermal Imaging</li>
          <ul>
            <li>Technology that could be explored and provide benefit to the Project idea but not in scope due to time
              constraints
            </li>
          </ul>
        </ul>
        <ul>
          <li>Integration with vehicle's in-built digital screen/navigation systems</li>
          <li>Android Application and Non-Apple Smart Watch expansion</li>
          <li>Expansion of reporting based on the data collected</li>
          <ul>
            <li>Initial reporting is limited to activity and rest game response time</li>
            <li>Further statistical reporting can be developed based on the collection of data</li>
          </ul>
          <li>Rest game improvements</li>
          <ul>
            <li>Initial game is very basic and only has left and right test to show functionality</li>
            <li>Future games can be developed with improvement on graphics and objects to test reaction times.
              For example, the user could touch a car image when it appears and not to touch pedestrian. Failure to
              react to the correct
              object could be used to measure reaction ability and speed
            </li>
          </ul>
          <li>Partnership with Insurance companies and a reward system that could be investigated. Driver could gain
            points and receive bonuses or improved insurance rates to encourage the use of this application. Insurance
            companies have used applications to encourage safe driving in this way in the past (Baker 2016)
          </li>
        </ul>

        <br>


        <h2 id="tools">Tools & Technologies</h2>
        <p>The tools and technologies we would need to possess to develop the Drive Aware app on an iOS would be,
          primarily the <a href="https://developer.apple.com/xcode/features/"> XCode developmental tool</a>. This is
          where we would be able to write our code using the <a href="https://docs.swift.org/swift-book/"> Swift
            Programming Language (Swift 5.4)</a> and build our user interface (UI). We would require database
          development to be able to store the user’s details and data gathered. This could be done with <a
              href="https://nordicapis.com/what-is-the-difference-between-an-api-and-an-sdk/"> SDK (Software Development
            Kit) and API (Application Programming Interface)</a>. The SPC (software processing control) will allow us to
          input the user’s personal data and <a href="https://www.w3schools.com/whatis/whatis_cli.asp"> CLI (Command
            Line Interface) </a>allows the input of specific details. </p>
        <p>The <a href="https://apple.fandom.com/wiki/Graphical_user_interface"> GUI- graphical user interface</a> will
          allow the reaction time game to function and <a
              href="https://developer.apple.com/documentation/xcode/allowing-apps-and-websites-to-link-to-your-content">
            URI- universal resource identifiers </a> can allow the app to call emergency services in a potential
          emergency. If Drive Aware were to be a native app, it would offer a better UX- user experience by having
          quicker navigation and enhanced security of the user’s data. Also being a <a
              href="https://www.webfx.com/blog/web-design/native-app-vs-mobile-web-app-comparison/"> native app</a>,
          this allows the camera to be accessed to then be able to monitor the driver’s visual cues with the
          forward-facing lens. </p>
        <p>As suggested in Assignment 2, the use of an <a href="https://www.healthline.com/health/eeg"> EEG
          (Electroencephalography) </a>head wear device, would help monitor if sleep were to occur by measuring the
          electro waves the brain emits. The waves that the EEG band will discover when a person is alert is<a
              href="https://www.sciencedirect.com/topics/medicine-and-dentistry/beta-wave"> Beta waves</a>. When a
          person is in a tired and almost falling asleep state, the EEG shows <a
              href="https://www.healthline.com/health/alpha-brain-waves"> Alpha waves</a>. This in conjunction with the
          <a ref="https://support.apple.com/en-au/guide/watch/apd0d5d452ce/watchos"> Apple Watch and iPhone measuring
            the biometrics</a> which will have a more accurate reading and perception of whether the driver is showing
          signs of drowsiness or imminent sleep. The EEG is a very promising future addition but at this stage we are
          exploring the benefits, but we want to keep the initial operation simple so, we will not be including this
          wearable technology in the first working prototype. </p>
        <img src="assets/newphoneimage.jpg" alt="apple watch and iphone" width="1200" height="500">
        <p>We would need to create icons to use in our app or we could use the <a href="https://freeiconshop.com/"> icon shop</a> which is open source for our user interface-UI. <a href="https://www.figma.com/files/recent?fuid=971228045439887774"> Figma </a>would be best to use to create our prototype as one of our valued team member Nicole, has had experience using it. If wanting to use <a href="https://developer.apple.com/fonts/"> Apple fonts</a>, we would require purchasing a licence. To create an Apple iOS app, you can use any Mac device and install the XCode programme which uses the swift coding language. You would need an Apple mac to work on for the <a href="https://www.macrumors.com/roundup/ios-14/"> iOS</a> version and have it updated to version iOS 14. An iPhone 6 and above and Apple watch will also be needed to test the app, after the app is complete. In the testing phase, an Apple Watch and the EEG headwear <a href="https://www.neeuro.com/senzeband/"> Neeuro-SenzeBand</a>, will be used together to create a more accurate reading. The headwear will work via <a href="https://electronics.howstuffworks.com/bluetooth.htm">Bluetooth</a> and operates on iOS and Android for future developments. In our case we are choosing Apple products to begin. When creating the <a href=”https://developer.android.com/”> Android </a> version<a href=”https://www.javascript.com/”> Java Script</a> will be used. </p>
        <h5> Meeting with Neeuro SenzeBand-With Gerard </h5>
        <video width="540" height="450" controls>
          <source src="./assets/Gerard_Interview.mp4" type="video/mp4">
         </video><img src="assets/GerardMeetingVeeuro.jpg" alt="gerards meeting with neero img" height="230" width="320">
         <br>
        <p>Another team member, Christopher Smith, has some experience in video editing with <a href="https://www.blackmagicdesign.com/au/products/davinciresolve/"> Davinci Resolve</a> and <a href="https://www.apple.com/au/imovie/"> iMovie</a> which will come in handy when we need to make out Assignment 5, and he also has some experience with <a href="https://careerfoundry.com/en/blog/ux-design/the-difference-between-ux-and-ui-design-a-laymans-guide/"> UI/UX </a>app design. Chris also has some experience with <a href="https://create-react-app.dev/"> React -Java Script framework</a> that makes cross platform smartphone apps. He also constructed most of a Minesweeper clone with a colleague in his past. Liljana has some experience with <a href="https://www.wix.com/"> WIX</a> s in web design and photo editing using the <a href="https://apps.apple.com/au/app/adobe-lightroom-photo-editor/id878783582"> Lightroom app</a>.  </p>
        <br>
        <h4>The Apple technologies we would need are:</h4>
        <p>The native <a href="https://developer.apple.com/xcode/swiftui/"> Swift UI </a> user interface which are used
          for building Apple apps. The developer tools below are used and integrated through Swift. The <a
              href="https://developer.apple.com/machine-learning/create-ml/"> Create ML </a>machine learning tool, this
          will be used to train the app on how to recognise a driver yawning, the rate of blinking and attentiveness.
          The <a href="https://developer.apple.com/documentation/coremotion"> Core Motion </a>reports motion from the
          accelerometers and gyroscopes, and from the pedometer, magnetometer, and barometer. <a
              href="https://developer.apple.com/documentation/corelocation"> Core Location </a>provides services that
          determine a device’s geographic location, altitude, and orientation used for GPS. User-facing notifications,
          communicate information to users of your app, regardless of whether your app is running on the user's device.
          <a href="https://developer.apple.com/documentation/pushkit"> The Push Kit framework</a> supports specialized
          notifications for updating your Watch OS (Operating System) complications.<a
              href="https://developer.apple.com/documentation/pushkit"> Push Kit </a>notifications launch the app and
          give it time to respond. Both Push Kit and User Notifications use the Apple Push Notification service (APNs)
          to deliver push notifications to the user device.
        </p>
        <p>As the system gathers information using various sensors on a device, <a
            href="https://developer.apple.com/documentation/sensorkit"> Sensor Kit</a> enables an app to access selected
          raw data, that the device obtains from a sensor <a href="https://developer.apple.com/documentation/healthkit">
            Health Kit</a> and provides a central repository for health and fitness data on an iPhone and Apple Watch.
          With the user’s permission, apps communicate with the Health Kit store to access and share their data. The <a
              href="https://developer.apple.com/documentation/systemconfiguration"> System Configuration</a> framework
          helps determine the reachability of the device, to see if the Wi-Fi or cell connectivity are active. The <a
              href="https://developer.apple.com/documentation/watchconnectivity"> Watch Connectivity framework</a>
          transfers data between iOS apps and the <a href="https://developer.apple.com/documentation/watchkit"> Watch
            Kit</a> extension of a paired Watch OS app. The Watch Kit framework provides the infrastructure including an
          extension that manages background tasks such as, extended runtime sessions and Siri intents which will operate
          with our vocal deactivation of alarms. </p>
        <p><a href="https://developer.apple.com/documentation/coreml"> Core ML </a>(Machine Learning) will be used to
          integrate machine learning models into our app. Apps use Core ML APIs (Application Programming Interfaces) and
          user data to make predictions, and to train or fine-tune models, all on the user’s device. This can help the
          drive Aware app operate more efficiently. </p>
        <p>In the event of a crash, the iPhones and Apple watches <a
            href="https://www.lifewire.com/iphone-gps-set-up-1683393"> GPS </a>can be used to help locate a driver if
          they have become separated from their vehicle. The <a
              href="https://developer.apple.com/documentation/coremotion/getting_raw_accelerometer_events">
            accelerometer </a>is used to measure the iPhones speed so then together with the <a
              href="https://developer.apple.com/documentation/coremotion/getting_raw_gyroscope_events"> Gyroscope</a>
          gatherer the Information to then determine, if a driver’s watch wearing arm is active such as, holding on to
          the steering wheel. </p>
        <p>The <a href="https://support.apple.com/en-au/HT210571"> forward-facing camera</a> will be monitoring the
          driver's visual cues and in conjunction with the <a
              href="https://developer.apple.com/machine-learning/">AI</a> (Artificial Intelligence) technology of the
          facial recognition, the wire frame will help determine whether the driver's facial expressions are showing
          signs of fatigue. This could be shown with yawning and slower eye movements. <a
              href="https://developer.apple.com/documentation/avfoundation/cameras_and_media_capture/avcam_building_a_camera_app">
            AV Cam</a> allows the App to capture photos with depth data and record video using the front and rear iPhone
          cameras. We believe this would help in getting the camera to detect visual cues. The <a
              href="https://support.apple.com/en-us/HT204666"> Apple Watch Heart Rate Monitor </a>will be used to
          monitor a driver’s heart rate while driving which will help determine the relaxed state of the user. <a
              href="https://developer.apple.com/documentation/healthkit"> Health Kit</a> provides a central repository
          for health and fitness data on iPhone and Apple Watch. With the user’s permission, apps communicate with the
          Health Kit store to access and share this data. The heart rate monitor reports to this and we would access the
          data from the Health Kit. </p>
        <br>
        <h4>Tools and Technologies coming together</h4>
        <p><a href="https://developer.apple.com/xcode/"> XCode</a> consists of a suite of tools, from creating your app
          to testing, optimizing, and submitting it to the <a href="https://www.apple.com/au/app-store/"> App Store</a>.<a
              href="https://www.makeuseof.com/tag/macbook-vs-imac/"> iMac or MacBook</a> will be used to design and code
          the App. <a href="https://developer.apple.com/swift/"> Swift </a> ensures your code is fast and efficient and
          safe for the user. iPhone and Apple watch will be used to test the functionality of the App during the testing
          phase. If we have access to the <a href="https://www.frontiersin.org/articles/10.3389/fninf.2020.553352/full">
            EEG head device</a> once the app has been created, we could also test to see if the accuracy is elevated. <a
              href="https://testflight.apple.com/"> TestFlight</a> makes it easy to invite users to test your apps and
          collect valuable feedback before releasing your apps on the App Store. You can invite up to 10,000 testers
          using just their email address or by sharing a public link. <a
              href="https://developer.apple.com/app-store-connect/api/"> The App Store Connect API</a> is a <a
              href="https://developer.apple.com/documentation/sign_in_with_apple"> REST API </a>that enables the
          automation of actions you take in App Store Connect. The App Store is a safe and trusted place for customers
          to discover apps, and a fantastic opportunity for developers to deliver apps and services across iPhone, iPad,
          Mac, Apple TV, and Apple Watch. </p>


        <h2 id="testing">Testing</h2>
        <h2 id="timeframe">Timeframe</h2>
        <h2 id="risks">Risks</h2>
        <h2 id="group">Group Processes & Communications</h2>
        <p>For Assignment 2, we did have another team member who was unresponsive to not only Microsoft Teams
          communication but also to direct emails via Canvas. This was addressed by making Anthony our Teacher and David
          our Tutor aware. We also removed the member from Teams.
          <br><br>The remaining 5 members of the DAT Team are very proactive and communicative. This has made the
          coordination of both Assignment 2 and 3 projects successful.
          <br><br>All members have notifications on for the Microsoft Teams group and therefore are very responsive to
          chat discussions, meeting invites and requests.
          <br><br>As all team members have different responsibilities and commitments at different times of the day. We
          have found that it is not always convenient to chat at the same time. We have navigated this with all members
          putting in the effort to regularly check regularly the chats.
          <br><br>Our team has agreed to twice weekly meetings so even if we have been busy with other commitments all
          team members have made the effort to attend in most cases.
        </p>

    </div>

  </div>

</div>

<!-- Optional JavaScript; choose one of the two! -->

<!-- Option 1: Bootstrap Bundle with Popper -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4"
        crossorigin="anonymous"></script>

<!-- Option 2: Separate Popper and Bootstrap JS -->
<!--
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js" integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.min.js" integrity="sha384-Atwg2Pkwv9vp0ygtn1JAojH0nYbwNJLPhwyoVbhoPwBhjQPR5VtM2+xf0Uwh9KtT" crossorigin="anonymous"></script>
-->

<script src="js/sidebars.js"></script>
</body>
</html>
